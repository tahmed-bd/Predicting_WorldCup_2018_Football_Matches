{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Non-ASCII character '\\xc3' in file datalab_beta.py on line 244, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details (datalab_beta.py, line 244)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"datalab_beta.py\"\u001b[0;36m, line \u001b[0;32m244\u001b[0m\n\u001b[0;31m    s = re.split(r'√Årea', s)[1].strip()\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Non-ASCII character '\\xc3' in file datalab_beta.py on line 244, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from matplotlib import style\n",
    "from scipy import stats\n",
    "style.use('seaborn-deep')\n",
    "from datalab_beta import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] File FinalDataSet/new/new/final_train_subset_feature.csv does not exist: 'FinalDataSet/new/new/final_train_subset_feature.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-16de0c1aedb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data_normal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FinalDataSet/new/new/final_train_subset_feature.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#train_data_normal=train_data_normal.drop('Unnamed: 0', 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#train_data_normal=train_data_normal.drop('team_1', 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#train_data_normal=train_data_normal.drop('team_2', 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kamrul/anaconda3/envs/dsa/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kamrul/anaconda3/envs/dsa/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kamrul/anaconda3/envs/dsa/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kamrul/anaconda3/envs/dsa/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kamrul/anaconda3/envs/dsa/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] File FinalDataSet/new/new/final_train_subset_feature.csv does not exist: 'FinalDataSet/new/new/final_train_subset_feature.csv'"
     ]
    }
   ],
   "source": [
    "train_data_normal=pd.read_csv('FinalDataSet/new/new/final_train_subset_feature.csv')\n",
    "#train_data_normal=train_data_normal.drop('Unnamed: 0', 1)\n",
    "#train_data_normal=train_data_normal.drop('team_1', 1)\n",
    "#train_data_normal=train_data_normal.drop('team_2', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>fifa_rank1</th>\n",
       "      <th>avg_age1</th>\n",
       "      <th>elo1</th>\n",
       "      <th>star_count1</th>\n",
       "      <th>coach_performance1</th>\n",
       "      <th>home_country_adv1</th>\n",
       "      <th>home_continent_adv1</th>\n",
       "      <th>last_best_performance1</th>\n",
       "      <th>final1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_players_goal</th>\n",
       "      <th>country_happiness_rank</th>\n",
       "      <th>gdp</th>\n",
       "      <th>population</th>\n",
       "      <th>happiness_score</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>freedom</th>\n",
       "      <th>generosity</th>\n",
       "      <th>goverment_corruption</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.521739</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>-0.042799</td>\n",
       "      <td>-0.075967</td>\n",
       "      <td>-0.095352</td>\n",
       "      <td>-0.240469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1659.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.043478</td>\n",
       "      <td>76.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-119.0</td>\n",
       "      <td>-1.719</td>\n",
       "      <td>-0.199030</td>\n",
       "      <td>-0.297282</td>\n",
       "      <td>-0.046465</td>\n",
       "      <td>-0.063681</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.130435</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.543</td>\n",
       "      <td>-0.041623</td>\n",
       "      <td>0.158836</td>\n",
       "      <td>-0.355033</td>\n",
       "      <td>0.039002</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.608696</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-1.208</td>\n",
       "      <td>-0.093117</td>\n",
       "      <td>0.089684</td>\n",
       "      <td>-0.095031</td>\n",
       "      <td>-0.055045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.478261</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-0.842</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>-0.131385</td>\n",
       "      <td>-0.347937</td>\n",
       "      <td>-0.128681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.956522</td>\n",
       "      <td>21.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-147.0</td>\n",
       "      <td>-0.905</td>\n",
       "      <td>-0.138415</td>\n",
       "      <td>-0.132643</td>\n",
       "      <td>-0.366083</td>\n",
       "      <td>-0.093787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.304348</td>\n",
       "      <td>61.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-1.807</td>\n",
       "      <td>-0.162399</td>\n",
       "      <td>-0.176004</td>\n",
       "      <td>-0.228461</td>\n",
       "      <td>-0.353721</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.608696</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.644373</td>\n",
       "      <td>-0.139180</td>\n",
       "      <td>0.017056</td>\n",
       "      <td>0.016982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.173913</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.684</td>\n",
       "      <td>0.108725</td>\n",
       "      <td>0.371416</td>\n",
       "      <td>-0.005513</td>\n",
       "      <td>0.059203</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.086957</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.088972</td>\n",
       "      <td>0.149781</td>\n",
       "      <td>0.215279</td>\n",
       "      <td>0.143958</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.260870</td>\n",
       "      <td>18.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>-0.859</td>\n",
       "      <td>-0.241579</td>\n",
       "      <td>-0.182617</td>\n",
       "      <td>-0.128199</td>\n",
       "      <td>-0.255915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173913</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.446</td>\n",
       "      <td>-0.069339</td>\n",
       "      <td>0.355002</td>\n",
       "      <td>0.178725</td>\n",
       "      <td>0.321116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.111936</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>0.020946</td>\n",
       "      <td>0.180359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>83.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-1.909</td>\n",
       "      <td>-0.192124</td>\n",
       "      <td>-0.218509</td>\n",
       "      <td>-0.443081</td>\n",
       "      <td>-0.178705</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.130435</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>-0.318448</td>\n",
       "      <td>-0.028138</td>\n",
       "      <td>0.028442</td>\n",
       "      <td>-0.117092</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1842.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.304348</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>1.438</td>\n",
       "      <td>0.290112</td>\n",
       "      <td>0.142420</td>\n",
       "      <td>-0.025003</td>\n",
       "      <td>-0.056153</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.347826</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1.228</td>\n",
       "      <td>0.027162</td>\n",
       "      <td>0.091673</td>\n",
       "      <td>-0.076368</td>\n",
       "      <td>-0.081418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.565217</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.198133</td>\n",
       "      <td>0.090307</td>\n",
       "      <td>0.062893</td>\n",
       "      <td>-0.071894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.869565</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.129068</td>\n",
       "      <td>0.129642</td>\n",
       "      <td>0.027481</td>\n",
       "      <td>-0.095370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>74.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-1.711</td>\n",
       "      <td>-0.249627</td>\n",
       "      <td>-0.159459</td>\n",
       "      <td>0.197109</td>\n",
       "      <td>-0.022153</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>1842.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.434783</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.051321</td>\n",
       "      <td>0.024399</td>\n",
       "      <td>-0.122419</td>\n",
       "      <td>0.099586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.347826</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.214300</td>\n",
       "      <td>0.020219</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.125453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.434783</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>1.306</td>\n",
       "      <td>-0.006151</td>\n",
       "      <td>0.238747</td>\n",
       "      <td>-0.138546</td>\n",
       "      <td>0.016637</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-118.0</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>-0.142957</td>\n",
       "      <td>-0.142678</td>\n",
       "      <td>-0.052263</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>24.9</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.086957</td>\n",
       "      <td>92.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-2.430</td>\n",
       "      <td>-0.776636</td>\n",
       "      <td>-0.232210</td>\n",
       "      <td>-0.244593</td>\n",
       "      <td>-0.127405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.434783</td>\n",
       "      <td>69.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.099</td>\n",
       "      <td>-0.207347</td>\n",
       "      <td>-0.411355</td>\n",
       "      <td>-0.070423</td>\n",
       "      <td>-0.326104</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.217391</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.086</td>\n",
       "      <td>0.204880</td>\n",
       "      <td>0.250090</td>\n",
       "      <td>0.181810</td>\n",
       "      <td>0.164620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.652174</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.740</td>\n",
       "      <td>0.190235</td>\n",
       "      <td>-0.154808</td>\n",
       "      <td>0.085684</td>\n",
       "      <td>-0.069491</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.739130</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>-0.031924</td>\n",
       "      <td>-0.050413</td>\n",
       "      <td>-0.049130</td>\n",
       "      <td>-0.107667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.739130</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-109.0</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.099180</td>\n",
       "      <td>-0.041837</td>\n",
       "      <td>0.282217</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>1574.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.869565</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.129068</td>\n",
       "      <td>-0.129642</td>\n",
       "      <td>-0.027481</td>\n",
       "      <td>0.095370</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173913</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.711</td>\n",
       "      <td>0.249627</td>\n",
       "      <td>0.159459</td>\n",
       "      <td>-0.197109</td>\n",
       "      <td>0.022153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>26.9</td>\n",
       "      <td>1727.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.434783</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>0.051321</td>\n",
       "      <td>-0.024399</td>\n",
       "      <td>0.122419</td>\n",
       "      <td>-0.099586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>32.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-0.727</td>\n",
       "      <td>-0.214300</td>\n",
       "      <td>-0.020219</td>\n",
       "      <td>-0.002943</td>\n",
       "      <td>-0.125453</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.434783</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-1.306</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>-0.238747</td>\n",
       "      <td>0.138546</td>\n",
       "      <td>-0.016637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.521739</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.142957</td>\n",
       "      <td>0.142678</td>\n",
       "      <td>0.052263</td>\n",
       "      <td>-0.010986</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.086957</td>\n",
       "      <td>-92.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>2.430</td>\n",
       "      <td>0.776636</td>\n",
       "      <td>0.232210</td>\n",
       "      <td>0.244593</td>\n",
       "      <td>0.127405</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.434783</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2.099</td>\n",
       "      <td>0.207347</td>\n",
       "      <td>0.411355</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.326104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.217391</td>\n",
       "      <td>85.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.086</td>\n",
       "      <td>-0.204880</td>\n",
       "      <td>-0.250090</td>\n",
       "      <td>-0.181810</td>\n",
       "      <td>-0.164620</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>1848.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.652174</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>-0.190235</td>\n",
       "      <td>0.154808</td>\n",
       "      <td>-0.085684</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.739130</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.031924</td>\n",
       "      <td>0.050413</td>\n",
       "      <td>0.049130</td>\n",
       "      <td>0.107667</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>1671.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.739130</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.099180</td>\n",
       "      <td>0.041837</td>\n",
       "      <td>-0.282217</td>\n",
       "      <td>-0.194444</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.913043</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-1.385</td>\n",
       "      <td>-0.504113</td>\n",
       "      <td>-0.127703</td>\n",
       "      <td>0.062896</td>\n",
       "      <td>-0.048300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.521739</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.384</td>\n",
       "      <td>-0.104447</td>\n",
       "      <td>-0.042855</td>\n",
       "      <td>-0.009451</td>\n",
       "      <td>-0.012639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.391304</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-124.0</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>-0.171867</td>\n",
       "      <td>-0.205609</td>\n",
       "      <td>-0.122833</td>\n",
       "      <td>-0.145099</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1659.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.173913</td>\n",
       "      <td>67.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-1.609</td>\n",
       "      <td>-0.069961</td>\n",
       "      <td>-0.167640</td>\n",
       "      <td>-0.018985</td>\n",
       "      <td>-0.159051</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.434783</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.156510</td>\n",
       "      <td>0.249143</td>\n",
       "      <td>-0.292140</td>\n",
       "      <td>-0.032892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.956522</td>\n",
       "      <td>50.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-1.168</td>\n",
       "      <td>-0.291250</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>-0.157924</td>\n",
       "      <td>0.016849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>29.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-1.080</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>-0.155785</td>\n",
       "      <td>-0.225518</td>\n",
       "      <td>-0.228268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.130435</td>\n",
       "      <td>53.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-1.569</td>\n",
       "      <td>-0.213721</td>\n",
       "      <td>-0.151605</td>\n",
       "      <td>-0.350880</td>\n",
       "      <td>-0.254135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.043478</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.525</td>\n",
       "      <td>0.638221</td>\n",
       "      <td>0.099567</td>\n",
       "      <td>-0.121490</td>\n",
       "      <td>0.033618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.521739</td>\n",
       "      <td>74.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-2.211</td>\n",
       "      <td>-0.132264</td>\n",
       "      <td>-0.371390</td>\n",
       "      <td>-0.227537</td>\n",
       "      <td>-0.110423</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.826087</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.120896</td>\n",
       "      <td>0.200194</td>\n",
       "      <td>0.264409</td>\n",
       "      <td>0.251625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.565217</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1.113</td>\n",
       "      <td>-0.101263</td>\n",
       "      <td>0.304590</td>\n",
       "      <td>0.129595</td>\n",
       "      <td>0.213449</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.695652</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>1.240</td>\n",
       "      <td>-0.034232</td>\n",
       "      <td>0.228738</td>\n",
       "      <td>-0.057776</td>\n",
       "      <td>0.070189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.415</td>\n",
       "      <td>-0.098622</td>\n",
       "      <td>-0.039939</td>\n",
       "      <td>-0.075936</td>\n",
       "      <td>-0.266901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1842.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.608696</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.214001</td>\n",
       "      <td>0.014717</td>\n",
       "      <td>0.037893</td>\n",
       "      <td>-0.104453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>1.822</td>\n",
       "      <td>0.185665</td>\n",
       "      <td>0.099565</td>\n",
       "      <td>-0.034454</td>\n",
       "      <td>-0.068792</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.739130</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>-1.647</td>\n",
       "      <td>-0.092944</td>\n",
       "      <td>-0.260346</td>\n",
       "      <td>-0.160864</td>\n",
       "      <td>0.015739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.217391</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.012756</td>\n",
       "      <td>0.031581</td>\n",
       "      <td>-0.261271</td>\n",
       "      <td>-0.014085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows √ó 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stage  fifa_rank1  avg_age1    elo1  star_count1  coach_performance1  \\\n",
       "0       0        70.0      28.1  1697.0          1.0                32.0   \n",
       "1       0        45.0      27.0  1659.0          1.0                15.0   \n",
       "2       0        41.0      27.2  1691.0          0.0                 8.0   \n",
       "3       0         4.0      27.7  1995.0          3.0                 5.0   \n",
       "4       0         7.0      26.4  1989.0          5.0                12.0   \n",
       "5       0         5.0      28.4  1984.0          4.0                 3.0   \n",
       "6       0        11.0      27.0  1881.0          0.0                11.0   \n",
       "7       0        20.0      27.5  1856.0          3.0                30.0   \n",
       "8       0        23.0      29.0  1746.0          1.0                28.0   \n",
       "9       0         1.0      25.7  2109.0          6.0                 1.0   \n",
       "10      0         2.0      27.8  2114.0          4.0                 2.0   \n",
       "11      0        24.0      27.4  1825.0          1.0                24.0   \n",
       "12      0         3.0      27.0  1927.0          5.0                21.0   \n",
       "13      0        21.0      26.8  1624.0          0.0                26.0   \n",
       "14      0        16.0      27.3  1927.0          3.0                 6.0   \n",
       "15      0         8.0      28.0  1842.0          2.0                18.0   \n",
       "16      0        70.0      28.1  1697.0          1.0                32.0   \n",
       "17      0         4.0      27.7  1995.0          3.0                 5.0   \n",
       "18      0        14.0      28.7  1866.0          3.0                 7.0   \n",
       "19      0        37.0      26.5  1799.0          0.0                14.0   \n",
       "20      0        12.0      26.1  1842.0          1.0                19.0   \n",
       "21      0         7.0      26.4  1989.0          5.0                12.0   \n",
       "22      0         5.0      28.4  1984.0          4.0                 3.0   \n",
       "23      0         2.0      27.8  2114.0          4.0                 2.0   \n",
       "24      0        48.0      24.9  1696.0          0.0                20.0   \n",
       "25      0        34.0      27.7  1769.0          0.0                31.0   \n",
       "26      0         3.0      27.0  1927.0          5.0                21.0   \n",
       "27      0        57.0      26.5  1760.0          1.0                25.0   \n",
       "28      0         1.0      25.7  2109.0          6.0                 1.0   \n",
       "29      0        21.0      25.9  1933.0          2.0                22.0   \n",
       "..    ...         ...       ...     ...          ...                 ...   \n",
       "66      0        67.0      28.7  1574.0          0.0                 9.0   \n",
       "67      0        10.0      28.0  2031.0          6.0                 4.0   \n",
       "68      0        36.0      26.9  1727.0          0.0                23.0   \n",
       "69      0        11.0      27.0  1881.0          0.0                11.0   \n",
       "70      0        20.0      27.5  1856.0          3.0                30.0   \n",
       "71      0        23.0      29.0  1746.0          1.0                28.0   \n",
       "72      0        22.0      29.0  1811.0          0.0                10.0   \n",
       "73      0         6.0      26.6  1866.0          0.0                13.0   \n",
       "74      0        21.0      26.8  1624.0          0.0                26.0   \n",
       "75      0        15.0      27.4  1848.0          0.0                16.0   \n",
       "76      0        24.0      27.4  1825.0          1.0                24.0   \n",
       "77      0        55.0      29.4  1671.0          0.0                17.0   \n",
       "78      0        27.0      26.4  1752.0          1.0                29.0   \n",
       "79      0        16.0      27.3  1927.0          3.0                 6.0   \n",
       "80      0        70.0      28.1  1697.0          1.0                32.0   \n",
       "81      0        45.0      27.0  1659.0          1.0                15.0   \n",
       "82      0         4.0      27.7  1995.0          3.0                 5.0   \n",
       "83      0        41.0      27.2  1691.0          0.0                 8.0   \n",
       "84      0         7.0      26.4  1989.0          5.0                12.0   \n",
       "85      0        11.0      27.0  1881.0          0.0                11.0   \n",
       "86      0         5.0      28.4  1984.0          4.0                 3.0   \n",
       "87      0        20.0      27.5  1856.0          3.0                30.0   \n",
       "88      0        24.0      27.4  1825.0          1.0                24.0   \n",
       "89      0         1.0      25.7  2109.0          6.0                 1.0   \n",
       "90      0         2.0      27.8  2114.0          4.0                 2.0   \n",
       "91      0        23.0      29.0  1746.0          1.0                28.0   \n",
       "92      0         8.0      28.0  1842.0          2.0                18.0   \n",
       "93      0        16.0      27.3  1927.0          3.0                 6.0   \n",
       "94      0        21.0      26.8  1624.0          0.0                26.0   \n",
       "95      0         3.0      27.0  1927.0          5.0                21.0   \n",
       "\n",
       "    home_country_adv1  home_continent_adv1  last_best_performance1  final1  \\\n",
       "0                 1.0                  1.0                    14.0     0.0   \n",
       "1                 0.0                  0.0                    51.0     0.0   \n",
       "2                 0.0                  0.0                    39.0     0.0   \n",
       "3                 0.0                  0.0                    24.0     0.0   \n",
       "4                 0.0                  1.0                     7.0     2.0   \n",
       "5                 0.0                  0.0                     4.0     5.0   \n",
       "6                 0.0                  0.0                    38.0     0.0   \n",
       "7                 0.0                  0.0                    34.0     0.0   \n",
       "8                 0.0                  0.0                    37.0     0.0   \n",
       "9                 0.0                  1.0                     2.0     8.0   \n",
       "10                0.0                  0.0                     1.0     7.0   \n",
       "11                0.0                  1.0                    12.0     1.0   \n",
       "12                0.0                  1.0                     9.0     0.0   \n",
       "13                0.0                  0.0                    35.0     0.0   \n",
       "14                0.0                  0.0                    31.0     0.0   \n",
       "15                0.0                  1.0                    22.0     0.0   \n",
       "16                1.0                  1.0                    14.0     0.0   \n",
       "17                0.0                  0.0                    24.0     0.0   \n",
       "18                0.0                  0.0                    10.0     2.0   \n",
       "19                0.0                  0.0                    36.0     0.0   \n",
       "20                0.0                  1.0                    40.0     0.0   \n",
       "21                0.0                  1.0                     7.0     2.0   \n",
       "22                0.0                  0.0                     4.0     5.0   \n",
       "23                0.0                  0.0                     1.0     7.0   \n",
       "24                0.0                  0.0                    30.0     0.0   \n",
       "25                0.0                  1.0                    11.0     0.0   \n",
       "26                0.0                  1.0                     9.0     0.0   \n",
       "27                0.0                  0.0                    15.0     0.0   \n",
       "28                0.0                  1.0                     2.0     8.0   \n",
       "29                0.0                  1.0                     8.0     1.0   \n",
       "..                ...                  ...                     ...     ...   \n",
       "66                0.0                  0.0                    33.0     0.0   \n",
       "67                0.0                  1.0                     6.0     1.0   \n",
       "68                0.0                  0.0                    32.0     0.0   \n",
       "69                0.0                  0.0                    38.0     0.0   \n",
       "70                0.0                  0.0                    34.0     0.0   \n",
       "71                0.0                  0.0                    37.0     0.0   \n",
       "72                0.0                  1.0                    77.0     0.0   \n",
       "73                0.0                  1.0                    13.0     0.0   \n",
       "74                0.0                  0.0                    35.0     0.0   \n",
       "75                0.0                  0.0                     5.0     0.0   \n",
       "76                0.0                  1.0                    12.0     1.0   \n",
       "77                0.0                  0.0                    77.0     0.0   \n",
       "78                0.0                  0.0                    54.0     0.0   \n",
       "79                0.0                  0.0                    31.0     0.0   \n",
       "80                1.0                  1.0                    14.0     0.0   \n",
       "81                0.0                  0.0                    51.0     0.0   \n",
       "82                0.0                  0.0                    24.0     0.0   \n",
       "83                0.0                  0.0                    39.0     0.0   \n",
       "84                0.0                  1.0                     7.0     2.0   \n",
       "85                0.0                  0.0                    38.0     0.0   \n",
       "86                0.0                  0.0                     4.0     5.0   \n",
       "87                0.0                  0.0                    34.0     0.0   \n",
       "88                0.0                  1.0                    12.0     1.0   \n",
       "89                0.0                  1.0                     2.0     8.0   \n",
       "90                0.0                  0.0                     1.0     7.0   \n",
       "91                0.0                  0.0                    37.0     0.0   \n",
       "92                0.0                  1.0                    22.0     0.0   \n",
       "93                0.0                  0.0                    31.0     0.0   \n",
       "94                0.0                  0.0                    35.0     0.0   \n",
       "95                0.0                  1.0                     9.0     0.0   \n",
       "\n",
       "    ...  avg_players_goal  country_happiness_rank    gdp  population  \\\n",
       "0   ...         -1.521739                    12.0   23.0       -38.0   \n",
       "1   ...         -3.043478                    76.0   87.0      -119.0   \n",
       "2   ...         -2.130435                   -24.0   33.0        23.0   \n",
       "3   ...          1.608696                    55.0    5.0        56.0   \n",
       "4   ...         -1.478261                    21.0   14.0       -35.0   \n",
       "5   ...          3.956522                    21.0   49.0      -147.0   \n",
       "6   ...          1.304348                    61.0   75.0       -73.0   \n",
       "7   ...          2.608696                   -18.0  -83.0       121.0   \n",
       "8   ...          2.173913                   -61.0  -31.0        21.0   \n",
       "9   ...         -2.086957                    -9.0  -53.0         8.0   \n",
       "10  ...          1.260870                    18.0   64.0       -93.0   \n",
       "11  ...         -0.173913                   -46.0  -17.0        64.0   \n",
       "12  ...          0.478261                   -13.0  -33.0       -54.0   \n",
       "13  ...         -1.000000                    83.0   96.0        57.0   \n",
       "14  ...         -3.130435                   -15.0   60.0        19.0   \n",
       "15  ...          2.304348                   -69.0 -100.0       -35.0   \n",
       "16  ...         -0.347826                   -55.0  -72.0        -5.0   \n",
       "17  ...          3.565217                     5.0  -89.0        44.0   \n",
       "18  ...          1.869565                    -9.0    8.0        86.0   \n",
       "19  ...          0.173913                    74.0   61.0       -11.0   \n",
       "20  ...         -2.434783                    -8.0   -1.0        60.0   \n",
       "21  ...         -0.347826                   -32.0  -60.0       -22.0   \n",
       "22  ...          2.434783                   -53.0   -3.0       -97.0   \n",
       "23  ...          0.521739                    10.0    8.0      -118.0   \n",
       "24  ...         -1.086957                    92.0  135.0      -171.0   \n",
       "25  ...         -1.434783                    69.0   87.0         4.0   \n",
       "26  ...          5.217391                   -85.0 -100.0        -2.0   \n",
       "27  ...         -5.652174                    30.0  -42.0        16.0   \n",
       "28  ...          3.739130                     7.0    6.0       -72.0   \n",
       "29  ...         -3.739130                   -11.0  -29.0      -109.0   \n",
       "..  ...               ...                     ...    ...         ...   \n",
       "66  ...         -1.869565                     9.0   -8.0       -86.0   \n",
       "67  ...         -0.173913                   -74.0  -61.0        11.0   \n",
       "68  ...          2.434783                     8.0    1.0       -60.0   \n",
       "69  ...          0.347826                    32.0   60.0        22.0   \n",
       "70  ...         -2.434783                    53.0    3.0        97.0   \n",
       "71  ...         -0.521739                   -10.0   -8.0       118.0   \n",
       "72  ...          1.086957                   -92.0 -135.0       171.0   \n",
       "73  ...          1.434783                   -69.0  -87.0        -4.0   \n",
       "74  ...         -5.217391                    85.0  100.0         2.0   \n",
       "75  ...          5.652174                   -30.0   42.0       -16.0   \n",
       "76  ...         -3.739130                    -7.0   -6.0        72.0   \n",
       "77  ...          3.739130                    11.0   29.0       109.0   \n",
       "78  ...         -3.913043                    64.0  130.0        61.0   \n",
       "79  ...         -1.521739                   -10.0   30.0        -7.0   \n",
       "80  ...         -3.391304                    21.0   15.0      -124.0   \n",
       "81  ...         -1.173913                    67.0   95.0       -33.0   \n",
       "82  ...          1.434783                   -19.0  -56.0        67.0   \n",
       "83  ...         -1.956522                    50.0   94.0        12.0   \n",
       "84  ...          0.956522                    29.0   15.0       -95.0   \n",
       "85  ...         -1.130435                    53.0   74.0       -13.0   \n",
       "86  ...          5.043478                   -71.0  -86.0        24.0   \n",
       "87  ...          1.521739                    74.0   52.0       -50.0   \n",
       "88  ...         -5.826087                   -16.0  -59.0        80.0   \n",
       "89  ...          3.565217                   -39.0  -11.0        -8.0   \n",
       "90  ...          2.695652                   -51.0  -23.0       -97.0   \n",
       "91  ...          0.739130                     8.0   56.0        25.0   \n",
       "92  ...         -1.608696                    -5.0   30.0        26.0   \n",
       "93  ...          0.782609                   -79.0  -70.0       -42.0   \n",
       "94  ...         -4.739130                    72.0   67.0       -52.0   \n",
       "95  ...          4.217391                    -2.0   -4.0        55.0   \n",
       "\n",
       "    happiness_score  life_expectancy   freedom  generosity  \\\n",
       "0            -0.381        -0.042799 -0.075967   -0.095352   \n",
       "1            -1.719        -0.199030 -0.297282   -0.046465   \n",
       "2             0.543        -0.041623  0.158836   -0.355033   \n",
       "3            -1.208        -0.093117  0.089684   -0.095031   \n",
       "4            -0.842         0.000579 -0.131385   -0.347937   \n",
       "5            -0.905        -0.138415 -0.132643   -0.366083   \n",
       "6            -1.807        -0.162399 -0.176004   -0.228461   \n",
       "7             0.219         0.644373 -0.139180    0.017056   \n",
       "8             1.684         0.108725  0.371416   -0.005513   \n",
       "9             0.373         0.088972  0.149781    0.215279   \n",
       "10           -0.859        -0.241579 -0.182617   -0.128199   \n",
       "11            1.446        -0.069339  0.355002    0.178725   \n",
       "12            0.439         0.111936 -0.010256    0.020946   \n",
       "13           -1.909        -0.192124 -0.218509   -0.443081   \n",
       "14            0.437        -0.318448 -0.028138    0.028442   \n",
       "15            1.438         0.290112  0.142420   -0.025003   \n",
       "16            1.228         0.027162  0.091673   -0.076368   \n",
       "17           -0.040         0.198133  0.090307    0.062893   \n",
       "18            0.110         0.129068  0.129642    0.027481   \n",
       "19           -1.711        -0.249627 -0.159459    0.197109   \n",
       "20            0.238        -0.051321  0.024399   -0.122419   \n",
       "21            0.727         0.214300  0.020219    0.002943   \n",
       "22            1.306        -0.006151  0.238747   -0.138546   \n",
       "23           -0.444        -0.142957 -0.142678   -0.052263   \n",
       "24           -2.430        -0.776636 -0.232210   -0.244593   \n",
       "25           -2.099        -0.207347 -0.411355   -0.070423   \n",
       "26            2.086         0.204880  0.250090    0.181810   \n",
       "27           -0.740         0.190235 -0.154808    0.085684   \n",
       "28           -0.333        -0.031924 -0.050413   -0.049130   \n",
       "29            0.262         0.099180 -0.041837    0.282217   \n",
       "..              ...              ...       ...         ...   \n",
       "66           -0.110        -0.129068 -0.129642   -0.027481   \n",
       "67            1.711         0.249627  0.159459   -0.197109   \n",
       "68           -0.238         0.051321 -0.024399    0.122419   \n",
       "69           -0.727        -0.214300 -0.020219   -0.002943   \n",
       "70           -1.306         0.006151 -0.238747    0.138546   \n",
       "71            0.444         0.142957  0.142678    0.052263   \n",
       "72            2.430         0.776636  0.232210    0.244593   \n",
       "73            2.099         0.207347  0.411355    0.070423   \n",
       "74           -2.086        -0.204880 -0.250090   -0.181810   \n",
       "75            0.740        -0.190235  0.154808   -0.085684   \n",
       "76            0.333         0.031924  0.050413    0.049130   \n",
       "77           -0.262        -0.099180  0.041837   -0.282217   \n",
       "78           -1.385        -0.504113 -0.127703    0.062896   \n",
       "79            0.384        -0.104447 -0.042855   -0.009451   \n",
       "80           -0.491        -0.171867 -0.205609   -0.122833   \n",
       "81           -1.609        -0.069961 -0.167640   -0.018985   \n",
       "82            0.503         0.156510  0.249143   -0.292140   \n",
       "83           -1.168        -0.291250 -0.000623   -0.157924   \n",
       "84           -1.080         0.051900 -0.155785   -0.225518   \n",
       "85           -1.569        -0.213721 -0.151605   -0.350880   \n",
       "86            1.525         0.638221  0.099567   -0.121490   \n",
       "87           -2.211        -0.132264 -0.371390   -0.227537   \n",
       "88            0.706         0.120896  0.200194    0.264409   \n",
       "89            1.113        -0.101263  0.304590    0.129595   \n",
       "90            1.240        -0.034232  0.228738   -0.057776   \n",
       "91           -0.415        -0.098622 -0.039939   -0.075936   \n",
       "92            0.053        -0.214001  0.014717    0.037893   \n",
       "93            1.822         0.185665  0.099565   -0.034454   \n",
       "94           -1.647        -0.092944 -0.260346   -0.160864   \n",
       "95            0.177         0.012756  0.031581   -0.261271   \n",
       "\n",
       "    goverment_corruption  winner  \n",
       "0              -0.240469       1  \n",
       "1              -0.063681      -1  \n",
       "2               0.039002      -1  \n",
       "3              -0.055045       0  \n",
       "4              -0.128681       1  \n",
       "5              -0.093787       0  \n",
       "6              -0.353721      -1  \n",
       "7               0.016982       1  \n",
       "8               0.059203      -1  \n",
       "9               0.143958      -1  \n",
       "10             -0.255915       0  \n",
       "11              0.321116       1  \n",
       "12              0.180359       1  \n",
       "13             -0.178705      -1  \n",
       "14             -0.117092      -1  \n",
       "15             -0.056153      -1  \n",
       "16             -0.081418       1  \n",
       "17             -0.071894       1  \n",
       "18             -0.095370       1  \n",
       "19             -0.022153      -1  \n",
       "20              0.099586       0  \n",
       "21              0.125453       1  \n",
       "22              0.016637      -1  \n",
       "23              0.010986       1  \n",
       "24             -0.127405       1  \n",
       "25             -0.326104      -1  \n",
       "26              0.164620       1  \n",
       "27             -0.069491      -1  \n",
       "28             -0.107667       1  \n",
       "29              0.194444       1  \n",
       "..                   ...     ...  \n",
       "66              0.095370      -1  \n",
       "67              0.022153       1  \n",
       "68             -0.099586       0  \n",
       "69             -0.125453      -1  \n",
       "70             -0.016637       1  \n",
       "71             -0.010986      -1  \n",
       "72              0.127405      -1  \n",
       "73              0.326104       1  \n",
       "74             -0.164620      -1  \n",
       "75              0.069491       1  \n",
       "76              0.107667      -1  \n",
       "77             -0.194444      -1  \n",
       "78             -0.048300       0  \n",
       "79             -0.012639       1  \n",
       "80             -0.145099      -1  \n",
       "81             -0.159051      -1  \n",
       "82             -0.032892       0  \n",
       "83              0.016849       0  \n",
       "84             -0.228268       0  \n",
       "85             -0.254135       1  \n",
       "86              0.033618       1  \n",
       "87             -0.110423       1  \n",
       "88              0.251625       1  \n",
       "89              0.213449      -1  \n",
       "90              0.070189       1  \n",
       "91             -0.266901       0  \n",
       "92             -0.104453       1  \n",
       "93             -0.068792       1  \n",
       "94              0.015739       1  \n",
       "95             -0.014085       1  \n",
       "\n",
       "[96 rows x 86 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_normal=pd.read_csv('FinalDataSet/new/new/test.csv')\n",
    "test_data_normal=test_data_normal.drop('Unnamed: 0', 1)\n",
    "test_data_normal=test_data_normal.drop('team_1', 1)\n",
    "test_data_normal=test_data_normal.drop('team_2', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>fifa_rank1</th>\n",
       "      <th>avg_age1</th>\n",
       "      <th>elo1</th>\n",
       "      <th>star_count1</th>\n",
       "      <th>coach_performance1</th>\n",
       "      <th>home_country_adv1</th>\n",
       "      <th>home_continent_adv1</th>\n",
       "      <th>last_best_performance1</th>\n",
       "      <th>final1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_players_goal</th>\n",
       "      <th>country_happiness_rank</th>\n",
       "      <th>gdp</th>\n",
       "      <th>population</th>\n",
       "      <th>happiness_score</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>freedom</th>\n",
       "      <th>generosity</th>\n",
       "      <th>goverment_corruption</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.695652</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.149329</td>\n",
       "      <td>-0.024297</td>\n",
       "      <td>0.020305</td>\n",
       "      <td>0.112763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.347826</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.259</td>\n",
       "      <td>-0.076627</td>\n",
       "      <td>0.080927</td>\n",
       "      <td>0.079994</td>\n",
       "      <td>0.162192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.130435</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.341611</td>\n",
       "      <td>0.034998</td>\n",
       "      <td>0.137870</td>\n",
       "      <td>0.037951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.217391</td>\n",
       "      <td>75.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-2.229</td>\n",
       "      <td>-0.091277</td>\n",
       "      <td>-0.370234</td>\n",
       "      <td>-0.107278</td>\n",
       "      <td>-0.357667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.478261</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.093427</td>\n",
       "      <td>0.024724</td>\n",
       "      <td>0.041359</td>\n",
       "      <td>-0.021681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.304348</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.971</td>\n",
       "      <td>-0.095384</td>\n",
       "      <td>0.034145</td>\n",
       "      <td>0.110931</td>\n",
       "      <td>0.087582</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.086957</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.027256</td>\n",
       "      <td>-0.007146</td>\n",
       "      <td>0.094850</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.391304</td>\n",
       "      <td>17.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-0.210308</td>\n",
       "      <td>-0.030703</td>\n",
       "      <td>-0.343760</td>\n",
       "      <td>-0.218759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.043478</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.125249</td>\n",
       "      <td>0.109170</td>\n",
       "      <td>0.045335</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.260870</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>-0.201540</td>\n",
       "      <td>-0.102317</td>\n",
       "      <td>-0.069153</td>\n",
       "      <td>-0.140250</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.025539</td>\n",
       "      <td>0.104734</td>\n",
       "      <td>-0.107375</td>\n",
       "      <td>0.118971</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.608696</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-119.0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>-0.153939</td>\n",
       "      <td>0.118011</td>\n",
       "      <td>-0.195739</td>\n",
       "      <td>-0.010140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-0.449</td>\n",
       "      <td>0.026374</td>\n",
       "      <td>-0.069549</td>\n",
       "      <td>-0.101741</td>\n",
       "      <td>-0.078841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.478261</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>-106.0</td>\n",
       "      <td>1.421</td>\n",
       "      <td>0.104047</td>\n",
       "      <td>0.252418</td>\n",
       "      <td>0.244771</td>\n",
       "      <td>0.222325</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.217391</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.012756</td>\n",
       "      <td>0.031581</td>\n",
       "      <td>-0.261271</td>\n",
       "      <td>-0.014085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.260870</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-107.0</td>\n",
       "      <td>1.149</td>\n",
       "      <td>0.143177</td>\n",
       "      <td>0.214450</td>\n",
       "      <td>-0.118241</td>\n",
       "      <td>0.129399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.695652</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.149329</td>\n",
       "      <td>0.024297</td>\n",
       "      <td>-0.020305</td>\n",
       "      <td>-0.112763</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-1.259</td>\n",
       "      <td>0.076627</td>\n",
       "      <td>-0.080927</td>\n",
       "      <td>-0.079994</td>\n",
       "      <td>-0.162192</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.130435</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.341611</td>\n",
       "      <td>-0.034998</td>\n",
       "      <td>-0.137870</td>\n",
       "      <td>-0.037951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>1842.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.217391</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>2.229</td>\n",
       "      <td>0.091277</td>\n",
       "      <td>0.370234</td>\n",
       "      <td>0.107278</td>\n",
       "      <td>0.357667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>1848.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.478261</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.093427</td>\n",
       "      <td>-0.024724</td>\n",
       "      <td>-0.041359</td>\n",
       "      <td>0.021681</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>-0.971</td>\n",
       "      <td>0.095384</td>\n",
       "      <td>-0.034145</td>\n",
       "      <td>-0.110931</td>\n",
       "      <td>-0.087582</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.086957</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.027256</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>-0.094850</td>\n",
       "      <td>-0.017391</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.391304</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.210308</td>\n",
       "      <td>0.030703</td>\n",
       "      <td>0.343760</td>\n",
       "      <td>0.218759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.043478</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-112.0</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.125249</td>\n",
       "      <td>-0.109170</td>\n",
       "      <td>-0.045335</td>\n",
       "      <td>-0.005559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.260870</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.201540</td>\n",
       "      <td>0.102317</td>\n",
       "      <td>0.069153</td>\n",
       "      <td>0.140250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.608696</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-0.570</td>\n",
       "      <td>-0.025539</td>\n",
       "      <td>-0.104734</td>\n",
       "      <td>0.107375</td>\n",
       "      <td>-0.118971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.608696</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-0.670</td>\n",
       "      <td>0.153939</td>\n",
       "      <td>-0.118011</td>\n",
       "      <td>0.195739</td>\n",
       "      <td>0.010140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.449</td>\n",
       "      <td>-0.026374</td>\n",
       "      <td>0.069549</td>\n",
       "      <td>0.101741</td>\n",
       "      <td>0.078841</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.478261</td>\n",
       "      <td>58.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-1.421</td>\n",
       "      <td>-0.104047</td>\n",
       "      <td>-0.252418</td>\n",
       "      <td>-0.244771</td>\n",
       "      <td>-0.222325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.217391</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.012756</td>\n",
       "      <td>-0.031581</td>\n",
       "      <td>0.261271</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.260870</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>-1.149</td>\n",
       "      <td>-0.143177</td>\n",
       "      <td>-0.214450</td>\n",
       "      <td>0.118241</td>\n",
       "      <td>-0.129399</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows √ó 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stage  fifa_rank1  avg_age1    elo1  star_count1  coach_performance1  \\\n",
       "0       1         7.0      26.4  1989.0          5.0                12.0   \n",
       "1       1        14.0      28.7  1866.0          3.0                 7.0   \n",
       "2       1        10.0      28.0  2031.0          6.0                 4.0   \n",
       "3       1        20.0      27.5  1856.0          3.0                30.0   \n",
       "4       1         2.0      27.8  2114.0          4.0                 2.0   \n",
       "5       1         3.0      27.0  1927.0          5.0                21.0   \n",
       "6       1        24.0      27.4  1825.0          1.0                24.0   \n",
       "7       1        16.0      27.3  1927.0          3.0                 6.0   \n",
       "8       2        14.0      28.7  1866.0          3.0                 7.0   \n",
       "9       2         2.0      27.8  2114.0          4.0                 2.0   \n",
       "10      2        24.0      27.4  1825.0          1.0                24.0   \n",
       "11      2        70.0      28.1  1697.0          1.0                32.0   \n",
       "12      3         7.0      26.4  1989.0          5.0                12.0   \n",
       "13      3        21.0      25.9  1933.0          2.0                22.0   \n",
       "14      4         3.0      27.0  1927.0          5.0                21.0   \n",
       "15      5         7.0      26.4  1989.0          5.0                12.0   \n",
       "16      1         5.0      28.4  1984.0          4.0                 3.0   \n",
       "17      1         4.0      27.7  1995.0          3.0                 5.0   \n",
       "18      1        70.0      28.1  1697.0          1.0                32.0   \n",
       "19      1        12.0      26.1  1842.0          1.0                19.0   \n",
       "20      1        15.0      27.4  1848.0          0.0                16.0   \n",
       "21      1        61.0      27.5  1706.0          0.0                27.0   \n",
       "22      1         6.0      26.6  1866.0          0.0                13.0   \n",
       "23      1        21.0      25.9  1933.0          2.0                22.0   \n",
       "24      2         7.0      26.4  1989.0          5.0                12.0   \n",
       "25      2         3.0      27.0  1927.0          5.0                21.0   \n",
       "26      2        21.0      25.9  1933.0          2.0                22.0   \n",
       "27      2        20.0      27.5  1856.0          3.0                30.0   \n",
       "28      3         3.0      27.0  1927.0          5.0                21.0   \n",
       "29      3        20.0      27.5  1856.0          3.0                30.0   \n",
       "30      4        21.0      25.9  1933.0          2.0                22.0   \n",
       "31      5        20.0      27.5  1856.0          3.0                30.0   \n",
       "\n",
       "    home_country_adv1  home_continent_adv1  last_best_performance1  final1  \\\n",
       "0                 0.0                  1.0                     7.0     2.0   \n",
       "1                 0.0                  0.0                    10.0     2.0   \n",
       "2                 0.0                  1.0                     6.0     1.0   \n",
       "3                 0.0                  0.0                    34.0     0.0   \n",
       "4                 0.0                  0.0                     1.0     7.0   \n",
       "5                 0.0                  1.0                     9.0     0.0   \n",
       "6                 0.0                  1.0                    12.0     1.0   \n",
       "7                 0.0                  0.0                    31.0     0.0   \n",
       "8                 0.0                  0.0                    10.0     2.0   \n",
       "9                 0.0                  0.0                     1.0     7.0   \n",
       "10                0.0                  1.0                    12.0     1.0   \n",
       "11                1.0                  1.0                    14.0     0.0   \n",
       "12                0.0                  1.0                     7.0     2.0   \n",
       "13                0.0                  1.0                     8.0     1.0   \n",
       "14                0.0                  1.0                     9.0     0.0   \n",
       "15                0.0                  1.0                     7.0     2.0   \n",
       "16                0.0                  0.0                     4.0     5.0   \n",
       "17                0.0                  0.0                    24.0     0.0   \n",
       "18                1.0                  1.0                    14.0     0.0   \n",
       "19                0.0                  1.0                    40.0     0.0   \n",
       "20                0.0                  0.0                     5.0     0.0   \n",
       "21                0.0                  0.0                    29.0     0.0   \n",
       "22                0.0                  1.0                    13.0     0.0   \n",
       "23                0.0                  1.0                     8.0     1.0   \n",
       "24                0.0                  1.0                     7.0     2.0   \n",
       "25                0.0                  1.0                     9.0     0.0   \n",
       "26                0.0                  1.0                     8.0     1.0   \n",
       "27                0.0                  0.0                    34.0     0.0   \n",
       "28                0.0                  1.0                     9.0     0.0   \n",
       "29                0.0                  0.0                    34.0     0.0   \n",
       "30                0.0                  1.0                     8.0     1.0   \n",
       "31                0.0                  0.0                    34.0     0.0   \n",
       "\n",
       "    ...  avg_players_goal  country_happiness_rank   gdp  population  \\\n",
       "0   ...         -3.695652                     7.0 -29.0       -10.0   \n",
       "1   ...         -0.347826                   -61.0   9.0        49.0   \n",
       "2   ...          2.130435                   -15.0 -29.0        19.0   \n",
       "3   ...          2.217391                    75.0  47.0        12.0   \n",
       "4   ...         -3.478261                    -3.0  -4.0        -6.0   \n",
       "5   ...         -0.304348                   -34.0  -7.0        67.0   \n",
       "6   ...         -1.086957                     5.0   9.0        -7.0   \n",
       "7   ...          1.391304                    17.0  63.0         7.0   \n",
       "8   ...          2.043478                    -3.0  21.0       112.0   \n",
       "9   ...         -1.260870                     5.0  48.0       -72.0   \n",
       "10  ...          0.608696                   -10.0 -11.0        69.0   \n",
       "11  ...         -2.608696                   -28.0   4.0      -119.0   \n",
       "12  ...         -3.000000                    14.0   6.0       -56.0   \n",
       "13  ...         -2.478261                   -58.0 -34.0      -106.0   \n",
       "14  ...          4.217391                    -2.0  -4.0        55.0   \n",
       "15  ...         -1.260870                   -46.0 -32.0      -107.0   \n",
       "16  ...          3.695652                    -7.0  29.0        10.0   \n",
       "17  ...          0.347826                    61.0  -9.0       -49.0   \n",
       "18  ...         -2.130435                    15.0  29.0       -19.0   \n",
       "19  ...         -2.217391                   -75.0 -47.0       -12.0   \n",
       "20  ...          3.478261                     3.0   4.0         6.0   \n",
       "21  ...          0.304348                    34.0   7.0       -67.0   \n",
       "22  ...          1.086957                    -5.0  -9.0         7.0   \n",
       "23  ...         -1.391304                   -17.0 -63.0        -7.0   \n",
       "24  ...         -2.043478                     3.0 -21.0      -112.0   \n",
       "25  ...          1.260870                    -5.0 -48.0        72.0   \n",
       "26  ...         -0.608696                    10.0  11.0       -69.0   \n",
       "27  ...          2.608696                    28.0  -4.0       119.0   \n",
       "28  ...          3.000000                   -14.0  -6.0        56.0   \n",
       "29  ...          2.478261                    58.0  34.0       106.0   \n",
       "30  ...         -4.217391                     2.0   4.0       -55.0   \n",
       "31  ...          1.260870                    46.0  32.0       107.0   \n",
       "\n",
       "    happiness_score  life_expectancy   freedom  generosity  \\\n",
       "0            -0.157         0.149329 -0.024297    0.020305   \n",
       "1             1.259        -0.076627  0.080927    0.079994   \n",
       "2             0.440         0.341611  0.034998    0.137870   \n",
       "3            -2.229        -0.091277 -0.370234   -0.107278   \n",
       "4             0.057        -0.093427  0.024724    0.041359   \n",
       "5             0.971        -0.095384  0.034145    0.110931   \n",
       "6            -0.210        -0.027256 -0.007146    0.094850   \n",
       "7            -0.357        -0.210308 -0.030703   -0.343760   \n",
       "8             0.012        -0.125249  0.109170    0.045335   \n",
       "9            -0.256        -0.201540 -0.102317   -0.069153   \n",
       "10            0.570         0.025539  0.104734   -0.107375   \n",
       "11            0.670        -0.153939  0.118011   -0.195739   \n",
       "12           -0.449         0.026374 -0.069549   -0.101741   \n",
       "13            1.421         0.104047  0.252418    0.244771   \n",
       "14            0.177         0.012756  0.031581   -0.261271   \n",
       "15            1.149         0.143177  0.214450   -0.118241   \n",
       "16            0.157        -0.149329  0.024297   -0.020305   \n",
       "17           -1.259         0.076627 -0.080927   -0.079994   \n",
       "18           -0.440        -0.341611 -0.034998   -0.137870   \n",
       "19            2.229         0.091277  0.370234    0.107278   \n",
       "20           -0.057         0.093427 -0.024724   -0.041359   \n",
       "21           -0.971         0.095384 -0.034145   -0.110931   \n",
       "22            0.210         0.027256  0.007146   -0.094850   \n",
       "23            0.357         0.210308  0.030703    0.343760   \n",
       "24           -0.012         0.125249 -0.109170   -0.045335   \n",
       "25            0.256         0.201540  0.102317    0.069153   \n",
       "26           -0.570        -0.025539 -0.104734    0.107375   \n",
       "27           -0.670         0.153939 -0.118011    0.195739   \n",
       "28            0.449        -0.026374  0.069549    0.101741   \n",
       "29           -1.421        -0.104047 -0.252418   -0.244771   \n",
       "30           -0.177        -0.012756 -0.031581    0.261271   \n",
       "31           -1.149        -0.143177 -0.214450    0.118241   \n",
       "\n",
       "    goverment_corruption  winner  \n",
       "0               0.112763       1  \n",
       "1               0.162192       1  \n",
       "2               0.037951       0  \n",
       "3              -0.357667       0  \n",
       "4              -0.021681       1  \n",
       "5               0.087582       1  \n",
       "6               0.017391       1  \n",
       "7              -0.218759       0  \n",
       "8               0.005559      -1  \n",
       "9              -0.140250      -1  \n",
       "10              0.118971      -1  \n",
       "11             -0.010140       0  \n",
       "12             -0.078841       1  \n",
       "13              0.222325      -1  \n",
       "14             -0.014085       1  \n",
       "15              0.129399       1  \n",
       "16             -0.112763      -1  \n",
       "17             -0.162192      -1  \n",
       "18             -0.037951       0  \n",
       "19              0.357667       0  \n",
       "20              0.021681      -1  \n",
       "21             -0.087582      -1  \n",
       "22             -0.017391      -1  \n",
       "23              0.218759       0  \n",
       "24             -0.005559       1  \n",
       "25              0.140250       1  \n",
       "26             -0.118971       1  \n",
       "27              0.010140       0  \n",
       "28              0.078841      -1  \n",
       "29             -0.222325       1  \n",
       "30              0.014085      -1  \n",
       "31             -0.129399      -1  \n",
       "\n",
       "[32 rows x 86 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data for Leave one out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loo_m_new=pd.read_csv('FinalDataSet/new/all_train_test_loo_28.csv')\n",
    "data_loo_m_new=data_loo_m_new.drop('Unnamed: 0', 1)\n",
    "#data_loo_m_new_dup=data_loo_m_new.drop_duplicates(subset=['team_1', 'team_2'], keep=False)\n",
    "#test_data_normal=test_data_normal.drop('team_1', 1)\n",
    "#test_data_normal=test_data_normal.drop('team_2', 1)\n",
    "# Drop the duplicate value\n",
    "#df = data_loo_m_new.drop_duplicates(['team_1','team_2'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 86 columns):\n",
      "team_1                     126 non-null object\n",
      "team_2                     126 non-null object\n",
      "fifa_rank1                 126 non-null float64\n",
      "avg_age1                   126 non-null float64\n",
      "elo1                       126 non-null float64\n",
      "star_count1                126 non-null float64\n",
      "coach_performance1         126 non-null float64\n",
      "home_country_adv1          126 non-null float64\n",
      "home_continent_adv1        126 non-null float64\n",
      "last_best_performance1     126 non-null float64\n",
      "final1                     126 non-null float64\n",
      "semi1                      126 non-null float64\n",
      "foreign_club1              126 non-null float64\n",
      "att1                       126 non-null float64\n",
      "def1                       126 non-null float64\n",
      "mid1                       126 non-null float64\n",
      "ovr1                       126 non-null float64\n",
      "power_index1               126 non-null float64\n",
      "offensive1                 126 non-null float64\n",
      "defensive1                 126 non-null float64\n",
      "avg_players_appearance1    126 non-null float64\n",
      "avg_players_goal1          126 non-null float64\n",
      "gdp1                       126 non-null float64\n",
      "population1                126 non-null float64\n",
      "country_happiness_rank1    126 non-null float64\n",
      "happiness_score1           126 non-null float64\n",
      "life_expectancy1           126 non-null float64\n",
      "freedom1                   126 non-null float64\n",
      "generosity1                126 non-null float64\n",
      "goverment_corruption1      126 non-null float64\n",
      "fifa_rank2                 126 non-null float64\n",
      "avg_age2                   126 non-null float64\n",
      "elo2                       126 non-null float64\n",
      "star_count2                126 non-null float64\n",
      "coach_performance2         126 non-null float64\n",
      "home_country_adv2          126 non-null float64\n",
      "home_continent_adv2        126 non-null float64\n",
      "last_best_performance2     126 non-null float64\n",
      "final2                     126 non-null float64\n",
      "semi2                      126 non-null float64\n",
      "foreign_club2              126 non-null float64\n",
      "att2                       126 non-null float64\n",
      "def2                       126 non-null float64\n",
      "mid2                       126 non-null float64\n",
      "ovr2                       126 non-null float64\n",
      "power_index2               126 non-null float64\n",
      "offensive2                 126 non-null float64\n",
      "defensive2                 126 non-null float64\n",
      "avg_players_appearance2    126 non-null float64\n",
      "avg_players_goal2          126 non-null float64\n",
      "gdp2                       126 non-null float64\n",
      "population2                126 non-null float64\n",
      "country_happiness_rank2    126 non-null float64\n",
      "happiness_score2           126 non-null float64\n",
      "life_expectancy2           126 non-null float64\n",
      "freedom2                   126 non-null float64\n",
      "generosity2                126 non-null float64\n",
      "goverment_corruption2      126 non-null float64\n",
      "fifa_rank                  126 non-null float64\n",
      "elo                        126 non-null float64\n",
      "avg_age                    126 non-null float64\n",
      "home_country_adv           126 non-null float64\n",
      "home_continent_adv         126 non-null float64\n",
      "last_best_performance      126 non-null float64\n",
      "star_count                 126 non-null float64\n",
      "coach_performance          126 non-null float64\n",
      "final                      126 non-null float64\n",
      "semi                       126 non-null float64\n",
      "foreign_club               126 non-null float64\n",
      "att                        126 non-null float64\n",
      "def                        126 non-null float64\n",
      "mid                        126 non-null float64\n",
      "ovr                        126 non-null float64\n",
      "power_index                126 non-null float64\n",
      "offensive                  126 non-null float64\n",
      "defensive                  126 non-null float64\n",
      "avg_players_appearance     126 non-null float64\n",
      "country_happiness_rank     126 non-null float64\n",
      "gdp                        126 non-null float64\n",
      "population                 126 non-null float64\n",
      "happiness_score            126 non-null float64\n",
      "life_expectancy            126 non-null float64\n",
      "freedom                    126 non-null float64\n",
      "generosity                 126 non-null float64\n",
      "goverment_corruption       126 non-null float64\n",
      "winner                     126 non-null int64\n",
      "dtypes: float64(83), int64(1), object(2)\n",
      "memory usage: 84.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data_loo_m_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_loo_m_new.duplicated(subset=None, keep='first')\n",
    "#duplicateRowsDF = data_loo_m_new_dup[data_loo_m_new_dup.duplicated()]\n",
    " \n",
    "#print(\"Duplicate Rows except first occurrence based on all columns are :\")\n",
    "#print(duplicateRowsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = data_loo_m_new[data_loo_m_new.duplicated('team_1','team_2') | ~data_loo_m_new.duplicated('team_1','team_2', keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_loo_m_new.loc[data_loo_m_new['team_2'] == 'england']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['team_2'] == 'england']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('FinalDataSet/new/all_train_test_loo_28.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1=pd.read_csv('FinalDataSet/new/all_train_test_loo_28.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_set_bf=pd.read_csv('FinalDataSet/bf.csv')\n",
    "final_data_set_bf=final_data_set_bf.drop('Unnamed: 0', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_set_bf1=final_data_set_bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loo_manual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-141d42cd9f09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_loo_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_data_set_bf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_loo_manual_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_data_set_bf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_loo_manual_best\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'team_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_loo_manual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'team_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata_loo_manual_best\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'team_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_loo_manual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'team_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_loo_manual_best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_loo_manual' is not defined"
     ]
    }
   ],
   "source": [
    "data_loo_best=final_data_set_bf\n",
    "data_loo_manual_best=final_data_set_bf\n",
    "data_loo_manual_best['team_1']=data_loo_manual['team_1']\n",
    "data_loo_manual_best['team_2']=data_loo_manual['team_2']\n",
    "data_loo_manual_best\n",
    "cols = list(data_loo_manual_best.columns.values)\n",
    "#cols\n",
    "data_loo_manual_best = data_loo_manual_best[['team_1',\n",
    " 'team_2','last_best_performance',\n",
    " 'offensive',\n",
    " 'att',\n",
    " 'power_index',\n",
    " 'coach_performance',\n",
    " 'life_expectancy',\n",
    " 'gdp',\n",
    " 'elo',\n",
    " 'goverment_corruption',\n",
    " 'generosity',\n",
    " 'happiness_score',\n",
    " 'semi',\n",
    " 'avg_age',\n",
    " 'winner']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the missing value for any features (all)\n",
    "In statistics, exploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "import missingno as msno\n",
    "msno.bar(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the missing value (Best Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(final_data_set_bf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(data, target_col='winner'):\n",
    "    features = data.drop(target_col, 1)\n",
    "    target = data[target_col]\n",
    "    x = to_array(features)\n",
    "    y = to_array(target)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data: Training and Testing(Conventional way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "train_data_normal.winner = train_data_normal.winner.apply(to_float)\n",
    "train_data_normal.replace(np.inf, np.nan)\n",
    "train_data_normal = train_data_normal.dropna()\n",
    "train_data_normal = train_data_normal.sample(frac=1)\n",
    "train=train_data_normal\n",
    "\n",
    "test_data_normal.winner = test_data_normal.winner.apply(to_float)\n",
    "test_data_normal.replace(np.inf, np.nan)\n",
    "test_data_normal = test_data_normal.dropna()\n",
    "test_data_normal = test_data_normal.sample(frac=1)\n",
    "test=test_data_normal\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "xx_train, yy_train = training(train, target_col='winner')\n",
    "\n",
    "#xx_train = preprocessing.scale(xx_train)\n",
    "xx_train = preprocessing.normalize(xx_train)\n",
    "xx_test, yy_test = training(test, target_col='winner')\n",
    "xx_test = preprocessing.normalize(xx_test)\n",
    "#xx_train = preprocessing.scale(xx_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix calculating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(actual_value, predicted_value):\n",
    "    class_target=[-1,0,1]\n",
    "    confusion_matrix=np.empty((3, 3)) \n",
    "    for i in class_target:\n",
    "        for j in class_target:\n",
    "            confusion_matrix[i][j]=0\n",
    "    for k in range(len(actual_value)):\n",
    "        a=int(actual_value[k])\n",
    "        b=int(predicted_value[k])\n",
    "        confusion_matrix[a][b]=confusion_matrix[a][b]+1\n",
    "    \n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate TP,TN,FP,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TP_calculate(df_confusion):\n",
    "    class_target=[-1,0,1]\n",
    "    TP= [None] * 3\n",
    "    for t in class_target:\n",
    "        for p in class_target:\n",
    "            if t==p:\n",
    "                TP[p]=df_confusion[t][p]\n",
    "    return TP\n",
    "def TN_calculate(df_confusion):\n",
    "    class_target=[-1,0,1]\n",
    "    TN= [None] * 3\n",
    "    TN[-1]=0\n",
    "    TN[1]=0\n",
    "    TN[0]=0\n",
    "    for t in class_target:\n",
    "        for p in class_target:\n",
    "            if t!=-1 and p!=-1:\n",
    "                TN[-1]=TN[-1]+df_confusion[t][p]\n",
    "            if t!=1 and p!=1:\n",
    "                TN[1]=TN[1]+df_confusion[t][p]\n",
    "            if t!=0 and p!=0:\n",
    "                TN[0]=TN[0]+df_confusion[t][p]\n",
    "    return TN\n",
    "def FP_calculate(df_confusion):\n",
    "    class_target=[-1,0,1]\n",
    "    FP= [None] * 3\n",
    "    FP[-1]=0\n",
    "    FP[1]=0\n",
    "    FP[0]=0\n",
    "    for t in class_target:\n",
    "        for p in class_target:\n",
    "            if t==p:\n",
    "                continue\n",
    "            else:\n",
    "                FP[p]=FP[p]+df_confusion[t][p]\n",
    "    return FP\n",
    "def FN_calculate(df_confusion):\n",
    "    class_target=[-1,0,1]\n",
    "    FN= [None] * 3\n",
    "    FN[-1]=0\n",
    "    FN[1]=0\n",
    "    FN[0]=0\n",
    "    for t in class_target:\n",
    "        for p in class_target:\n",
    "            if t==p:\n",
    "                continue\n",
    "            else:\n",
    "                FN[t]=FN[t]+df_confusion[t][p]\n",
    "    return FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating precision, recall, f-score, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def avg(values):\n",
    "    values=np.nan_to_num(values)\n",
    "    sum=0\n",
    "    for i in values:\n",
    "        sum=sum+i\n",
    "    avg=sum/float(3)\n",
    "    return avg\n",
    "def calculate_precision(actual_value, predicted_value):\n",
    "    class_target=[-1,0,1]\n",
    "    precision= [None] * 3\n",
    "    precision[0]=0\n",
    "    precision[-1]=0\n",
    "    precision[1]=0\n",
    "    confusion_matrix=calculate_confusion_matrix(actual_value, predicted_value)\n",
    "    TP=TP_calculate(confusion_matrix)\n",
    "    TN=TN_calculate(confusion_matrix)\n",
    "    FP=FP_calculate(confusion_matrix)\n",
    "    FN=FN_calculate(confusion_matrix)\n",
    "    #precision=sum_list(TP)/float(sum_list(TP)+sum_list(FP))\n",
    "    for i in class_target:\n",
    "        precision[i]=TP[i]/float(TP[i]+FP[i])\n",
    "    return precision\n",
    "def calculate_recall(actual_value, predicted_value):\n",
    "    class_target=[-1,0,1]\n",
    "    recall= [None] * 3\n",
    "    recall[0]=0\n",
    "    recall[1]=0\n",
    "    recall[-1]=0\n",
    "    confusion_matrix=calculate_confusion_matrix(actual_value, predicted_value)\n",
    "    TP=TP_calculate(confusion_matrix)\n",
    "    TN=TN_calculate(confusion_matrix)\n",
    "    FP=FP_calculate(confusion_matrix)\n",
    "    FN=FN_calculate(confusion_matrix)\n",
    "    for x in class_target:\n",
    "        recall[x]=(TP[x])/float((TP[x])+(FN[x]))\n",
    "    return recall\n",
    "def calculate_f_score(actual_value, predicted_value):\n",
    "    class_target=[-1,0,1]\n",
    "    f_score= [None] * 3\n",
    "    f_score[0]=0\n",
    "    f_score[1]=0\n",
    "    f_score[-1]=0\n",
    "    #confusion_matrix=calculate_confusion_matrix(actual_value, predicted_value)\n",
    "    precision=calculate_precision(actual_value,predicted_value)\n",
    "    recall=calculate_recall(actual_value,predicted_value)\n",
    "    for y in class_target:\n",
    "        if (recall[y]+precision[y])==0:\n",
    "            f_score[y]=0\n",
    "        else:\n",
    "            f_score[y]=(2.0*recall[y]*precision[y])/float(recall[y]+precision[y])\n",
    "    return f_score\n",
    "def calculate_accuracy(actual_value,predicted_value):\n",
    "    class_target=[-1,0,1]\n",
    "    accuracy= [None] * 3\n",
    "    accuracy[0]=0\n",
    "    accuracy[1]=0\n",
    "    accuracy[-1]=0\n",
    "    confusion_matrix=calculate_confusion_matrix(actual_value, predicted_value)\n",
    "    TP=TP_calculate(confusion_matrix)\n",
    "    TN=TN_calculate(confusion_matrix)\n",
    "    FP=FP_calculate(confusion_matrix)\n",
    "    FN=FN_calculate(confusion_matrix)\n",
    "    for z in class_target:\n",
    "        accuracy[z]=(TP[z]+TN[z])/float(TP[z]+TN[z]+FP[z]+FN[z])\n",
    "    return accuracy\n",
    "def calculate_accuracy_score(actual_value,predicted_value):\n",
    "    count=0\n",
    "    length=len(actual_value)\n",
    "    for i in range(length):\n",
    "        if actual_value[i]==predicted_value[i]:\n",
    "            count=count+1\n",
    "    accuracy=count/float(length)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_matrix(confusion_matrix):\n",
    "    class_target=[-1,0,1]\n",
    "    precision= [None] * 3\n",
    "    precision[0]=0.0\n",
    "    precision[-1]=0.0\n",
    "    precision[1]=0.0\n",
    "    TP=TP_calculate(confusion_matrix)\n",
    "    TN=TN_calculate(confusion_matrix)\n",
    "    FP=FP_calculate(confusion_matrix)\n",
    "    FN=FN_calculate(confusion_matrix)\n",
    "    #precision=sum_list(TP)/float(sum_list(TP)+sum_list(FP))\n",
    "    for i in class_target:\n",
    "        precision[i]=TP[i]/float(TP[i]+FP[i])\n",
    "    return precision\n",
    "def calculate_recall_matrix(confusion_matrix):\n",
    "    class_target=[-1,0,1]\n",
    "    recall= [None] * 3\n",
    "    recall[0]=0.0\n",
    "    recall[1]=0.0\n",
    "    recall[-1]=0.0\n",
    "    TP=TP_calculate(confusion_matrix)\n",
    "    TN=TN_calculate(confusion_matrix)\n",
    "    FP=FP_calculate(confusion_matrix)\n",
    "    FN=FN_calculate(confusion_matrix)\n",
    "    for x in class_target:\n",
    "        recall[x]=(TP[x])/float((TP[x])+(FN[x]))\n",
    "    return recall\n",
    "def calculate_f_score_matrix(confusion_matrix):\n",
    "    class_target=[-1,0,1]\n",
    "    f_score= [None] * 3\n",
    "    f_score[0]=0.0\n",
    "    f_score[1]=0.0\n",
    "    f_score[-1]=0.0\n",
    "    #confusion_matrix=calculate_confusion_matrix(actual_value, predicted_value)\n",
    "    precision=calculate_precision_matrix(confusion_matrix)\n",
    "    recall=calculate_recall_matrix(confusion_matrix)\n",
    "    for y in class_target:\n",
    "        if (recall[y]+precision[y])==0:\n",
    "            f_score[y]=0\n",
    "        else:\n",
    "            f_score[y]=(2.0*recall[y]*precision[y])/float(recall[y]+precision[y])\n",
    "    return f_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (All Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(xx_train, yy_train)\n",
    "predicted_value_lr = lr.predict(xx_test)\n",
    "lr_precision=calculate_precision(yy_test, predicted_value_lr)\n",
    "lr_recall=calculate_recall(yy_test, predicted_value_lr)\n",
    "lr_f_score=calculate_f_score(yy_test, predicted_value_lr)\n",
    "lr_accuracy=calculate_accuracy(yy_test, predicted_value_lr)\n",
    "lr_accuracy_score=calculate_accuracy_score(yy_test, predicted_value_lr)\n",
    "lr_confusion=calculate_confusion_matrix(yy_test,predicted_value_lr)\n",
    "lr_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with RandomForestClassifier (all Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(xx_train, yy_train)\n",
    "predicted_value_rf = rf.predict(xx_test)\n",
    "rf_precision=calculate_precision(yy_test, predicted_value_rf)\n",
    "rf_recall=calculate_recall(yy_test, predicted_value_rf)\n",
    "rf_f_score=calculate_f_score(yy_test, predicted_value_rf)\n",
    "rf_accuracy=calculate_accuracy(yy_test, predicted_value_rf)\n",
    "rf_accuracy_score=calculate_accuracy_score(yy_test, predicted_value_rf)\n",
    "rf_confusion=calculate_confusion_matrix(yy_test, predicted_value_rf)\n",
    "rf_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Support Vector Machine (All Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "svc.fit(xx_train, yy_train)\n",
    "predicted_value_svc = svc.predict(xx_test)\n",
    "svc_precision=calculate_precision(yy_test, predicted_value_svc)\n",
    "svc_recall=calculate_recall(yy_test, predicted_value_svc)\n",
    "svc_f_score=calculate_f_score(yy_test, predicted_value_svc)\n",
    "svc_accuracy=calculate_accuracy(yy_test, predicted_value_svc)\n",
    "svc_accuracy_score=calculate_accuracy_score(yy_test, predicted_value_svc)\n",
    "svc_confusion=calculate_confusion_matrix(yy_test, predicted_value_svc)\n",
    "svc_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Comparison without best features, best param and CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize']=(25,10)\n",
    "plt.style.use('ggplot')\n",
    "label=['Logistic Regression','Random Forest Classifier','Support Vector Machine']\n",
    "score=[lr_accuracy_score,rf_accuracy_score,svc_accuracy_score]\n",
    "index = np.arange(len(label))\n",
    "plt.bar(index, score)\n",
    "plt.xlabel('Model', fontsize=50)\n",
    "plt.ylabel('Score', fontsize=50)\n",
    "plt.xticks(index, label, fontsize=30, rotation=0)\n",
    "plt.title('Model comparison')\n",
    "for a,b in zip(index, score):\n",
    "    plt.text(a, b, str(b),size=20)\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig('Features_normalise.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data : Training and Testing : Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_set_bf1=final_data_set_bf1.drop('team_1', 1)\n",
    "final_data_set_bf1=final_data_set_bf1.drop('team_2', 1)\n",
    "final_data_set_bf1.winner = final_data_set_bf1.winner.apply(to_float)\n",
    "final_data_set_bf1.replace(np.inf, np.nan)\n",
    "final_data_set_bf1 = final_data_set_bf1.dropna()\n",
    "final_data_set_bf1 = final_data_set_bf1.sample(frac=1)\n",
    "train_best, test_best = train_test_split(final_data_set_bf1, 0.2)\n",
    "train_best.reset_index(drop=True, inplace=True)\n",
    "xx_train_best, yy_train_best = training(train_best, target_col='winner')\n",
    "xx_test_best, yy_test_best = training(test_best, target_col='winner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with LogisticRegression (Best Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bf = LogisticRegression()\n",
    "lr_bf.fit(xx_train_best, yy_train_best)\n",
    "predicted_value_lr_bf = lr_bf.predict(xx_test_best)\n",
    "lr_precision_bf=calculate_precision(yy_test_best, predicted_value_lr_bf)\n",
    "lr_recall_bf=calculate_recall(yy_test_best, predicted_value_lr_bf)\n",
    "lr_f_score_bf=calculate_f_score(yy_test_best, predicted_value_lr_bf)\n",
    "lr_accuracy_bf=calculate_accuracy(yy_test_best, predicted_value_lr_bf)\n",
    "lr_accuracy_score_bf=calculate_accuracy_score(yy_test_best, predicted_value_lr_bf)\n",
    "lr_confusion_bf=calculate_confusion_matrix(yy_test_best,predicted_value_lr_bf)\n",
    "lr_confusion_bf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with RandomForestClassifier (Best Features)¬∂\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bf = RandomForestClassifier()\n",
    "rf_bf.fit(xx_train_best, yy_train_best)\n",
    "predicted_value_rf_bf = rf_bf.predict(xx_test_best)\n",
    "rf_precision_bf=calculate_precision(yy_test_best, predicted_value_rf_bf)\n",
    "rf_recall_bf=calculate_recall(yy_test_best, predicted_value_rf_bf)\n",
    "rf_f_score_bf=calculate_f_score(yy_test_best, predicted_value_rf_bf)\n",
    "rf_accuracy_bf=calculate_accuracy(yy_test_best, predicted_value_rf_bf)\n",
    "rf_accuracy_score_bf=calculate_accuracy_score(yy_test_best, predicted_value_rf_bf)\n",
    "rf_confusion_bf=calculate_confusion_matrix(yy_test_best, predicted_value_rf_bf)\n",
    "rf_confusion_bf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Support Vector Machine (Best Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_bf = SVC(kernel='linear')\n",
    "svc_bf.fit(xx_train_best, yy_train_best)\n",
    "predicted_value_svc_bf = svc_bf.predict(xx_test_best)\n",
    "svc_precision_bf=calculate_precision(yy_test_best, predicted_value_svc_bf)\n",
    "svc_recall_bf=calculate_recall(yy_test_best, predicted_value_svc_bf)\n",
    "svc_f_score_bf=calculate_f_score(yy_test_best, predicted_value_svc_bf)\n",
    "svc_accuracy_bf=calculate_accuracy(yy_test_best, predicted_value_svc_bf)\n",
    "svc_accuracy_score_bf=calculate_accuracy_score(yy_test_best, predicted_value_svc_bf)\n",
    "svc_confusion_bf=calculate_confusion_matrix(yy_test_best, predicted_value_svc_bf)\n",
    "svc_confusion_bf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Comparison with best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize']=(25,10)\n",
    "plt.style.use('ggplot')\n",
    "n = 3\n",
    "#print(\"Manaully\",\"Svc: \", accu_svc, \"Lr: \", accu_lr, \"RF \", accu_rf)\n",
    "#print(\"From Scikit\",\"Svc: \", al_svcr,\"Lr: \", al_lr,\"RF: \", al_rf)\n",
    "#without_CV=(svc_accuracy_score,lr_accuracy_score,rf_accuracy_score)\n",
    "without_best_features=(svc_accuracy_score,lr_accuracy_score,rf_accuracy_score)\n",
    "with_best_features=(svc_accuracy_score_bf,lr_accuracy_score_bf,rf_accuracy_score_bf)\n",
    "#Loo_CV_manual=(accu_svc,accu_lr,accu_rf)\n",
    "#milan= (73, 43, 44, 70, 61)\n",
    "#inter = (54, 59, 69, 46, 58)\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n)\n",
    "bar_width = 0.25\n",
    "opacity = 0.9\n",
    "ax.bar(index, without_best_features, bar_width, alpha=opacity, color='r',\n",
    "                label='Without Best Features')\n",
    "ax.bar(index+bar_width, with_best_features, bar_width, alpha=opacity, color='b',label='With Best Features')\n",
    "\n",
    "#ax.bar(index+bar_width+bar_width, Loo_CV_manual, bar_width, alpha=opacity, color='g', label='LOO CV Manual')\n",
    "ax.set_xlabel('Model',fontsize=30)\n",
    "ax.set_ylabel('Score',fontsize=30)\n",
    "ax.set_title('Model comparison with best Features',fontsize=40)\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(('Support Vector','Logistic Regression','Random Forest'),size=30)\n",
    "ax.legend()\n",
    "plt.savefig('Best_Features.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypermeter for logisric regression with gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logistic = LogisticRegression()\n",
    "penalty = ['l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "solver=['newton-cg','saga','sag','liblinear']\n",
    "hyperparameters = dict(C=C, penalty=penalty,solver=solver) \n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=2, verbose=1) \n",
    "best_model = gridsearch.fit(xx_train, yy_train)\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best solver:', best_model.best_estimator_.get_params()['solver'])\n",
    "print(\"The mean accuracy of the model is:\",best_model.score(xx_train, yy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypermeter for logisric regression with gridsearch (Best Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logistic_best = LogisticRegression()\n",
    "penalty = ['l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "solver=['newton-cg','saga','sag','liblinear']\n",
    "hyperparameters = dict(C=C, penalty=penalty,solver=solver) \n",
    "gridsearch_lr_best = GridSearchCV(logistic_best, hyperparameters, cv=2, verbose=1) \n",
    "best_model_lr_bf = gridsearch_lr_best.fit(xx_train_best, yy_train_best)\n",
    "print('Best Penalty:', best_model_lr_bf.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model_lr_bf.best_estimator_.get_params()['C'])\n",
    "print('Best solver:', best_model_lr_bf.best_estimator_.get_params()['solver'])\n",
    "print(\"The mean accuracy of the model is:\",best_model_lr_bf.score(xx_train_best, yy_train_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypermeter for support vector machine with gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "degree=[0, 1, 2, 3, 4, 5, 6]\n",
    "kernel=['linear', 'rbf', 'poly']\n",
    "gamma=[0.1, 1, 10, 100]\n",
    "C=np.logspace(0.1, 1, 10, 100, 1000)\n",
    "hyperparameters = dict(C=C, degree=degree, kernel=kernel, gamma=gamma)\n",
    "gridsearch_svc = GridSearchCV(svc, hyperparameters, cv=2, verbose=1)\n",
    "best_model_svc = gridsearch_svc.fit(xx_train, yy_train)\n",
    "print('Best Degree:', best_model_svc.best_estimator_.get_params()['degree'])\n",
    "print('Best C:', best_model_svc.best_estimator_.get_params()['C'])\n",
    "print('Best Kernel:', best_model_svc.best_estimator_.get_params()['kernel'])\n",
    "print('Best Gamma:', best_model_svc.best_estimator_.get_params()['gamma'])\n",
    "print(\"The mean accuracy of the model is:\",best_model_svc.score(xx_train, yy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypermeter for support vector machine with gridsearch (Best Features) not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_best = SVC()\n",
    "degree=[0, 1, 2, 3, 4, 5, 6]\n",
    "kernel=['linear', 'rbf', 'poly']\n",
    "gamma=[0.1, 1, 10, 100]\n",
    "C=np.logspace(0.1, 1, 10, 100, 1000)\n",
    "hyperparameters = dict(C=C, degree=degree, kernel=kernel, gamma=gamma)\n",
    "gridsearch_svc_bf = GridSearchCV(svc_best, hyperparameters, cv=2, verbose=1)\n",
    "best_model_svc_bf = gridsearch_svc_bf.fit(xx_train_best, yy_train_best)\n",
    "print('Best Degree:', best_model_svc_bf.best_estimator_.get_params()['degree'])\n",
    "print('Best C:', best_model_svc_bf.best_estimator_.get_params()['C'])\n",
    "print('Best Kernel:', best_model_svc_bf.best_estimator_.get_params()['kernel'])\n",
    "print('Best Gamma:', best_model_svc_bf.best_estimator_.get_params()['gamma'])\n",
    "print(\"The mean accuracy of the model is:\",best_model_svc_bf.score(xx_train_best, yy_train_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypermeter for random forest classifier with gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier()\n",
    "n_estimators=[10, 100, 1000]\n",
    "max_depth=[5,8,15,25,30,None]\n",
    "min_samples_leaf=[1,2,5,10,15,100]\n",
    "max_leaf_nodes=[2, 5,10]\n",
    "hyperparameters = dict(n_estimators=n_estimators, max_depth=max_depth,min_samples_leaf=min_samples_leaf, max_leaf_nodes=max_leaf_nodes) \n",
    "gridsearch_rf = GridSearchCV(RF, hyperparameters, cv=2, verbose=1) \n",
    "best_model_rf = gridsearch_rf.fit(xx_train, yy_train)\n",
    "print('Best n_estimators:', best_model_rf.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best max_depth:', best_model_rf.best_estimator_.get_params()['max_depth'])\n",
    "print('Best min_samples_leaf:', best_model_rf.best_estimator_.get_params()['min_samples_leaf'])\n",
    "print('Best max_leaf_nodes:', best_model_rf.best_estimator_.get_params()['max_leaf_nodes'])\n",
    "print(\"The mean accuracy of the model is:\",best_model_rf.score(xx_train, yy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypermeter for random forest classifier with gridsearch (Best Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_best = RandomForestClassifier()\n",
    "n_estimators=[10, 100, 1000]\n",
    "max_depth=[5,8,15,25,30,None]\n",
    "min_samples_leaf=[1,2,5,10,15,100]\n",
    "max_leaf_nodes=[2, 5,10]\n",
    "hyperparameters = dict(n_estimators=n_estimators, max_depth=max_depth,min_samples_leaf=min_samples_leaf, max_leaf_nodes=max_leaf_nodes) \n",
    "gridsearch_rf_bf = GridSearchCV(RF_best, hyperparameters, cv=2, verbose=1) \n",
    "best_model_rf_bf = gridsearch_rf_bf.fit(xx_train_best, yy_train_best)\n",
    "print('Best n_estimators:', best_model_rf_bf.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best max_depth:', best_model_rf_bf.best_estimator_.get_params()['max_depth'])\n",
    "print('Best min_samples_leaf:', best_model_rf_bf.best_estimator_.get_params()['min_samples_leaf'])\n",
    "print('Best max_leaf_nodes:', best_model_rf_bf.best_estimator_.get_params()['max_leaf_nodes'])\n",
    "print(\"The mean accuracy of the model is:\",best_model_rf_bf.score(xx_train_best, yy_train_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave one out cross validation (LOOCV) From scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using Leave One Out Cross Validation\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "data_loo.winner = data_loo.winner.apply(to_float)\n",
    "data_loo.replace(np.inf, np.nan)\n",
    "data_loo = data_loo.dropna()\n",
    "data_loo = data_loo.sample(frac=1)\n",
    "array = data_loo.values\n",
    "XX = array[:,0:83]\n",
    "YY = array[:,83]\n",
    "#print(XX)\n",
    "num_folds = 96\n",
    "#num_instances = len(XX)\n",
    "loocv = model_selection.LeaveOneOut()\n",
    "model1 = LogisticRegression()\n",
    "#model2=SVC(kernel='linear') # svc has problem\n",
    "model3 = RandomForestClassifier()\n",
    "results1 = model_selection.cross_val_score(model1, XX, YY, cv=loocv)\n",
    "#results2 = model_selection.cross_val_score(model2, XX, YY, cv=loocv)\n",
    "results3 = model_selection.cross_val_score(model3, XX, YY, cv=loocv)\n",
    "#print(results)\n",
    "#print(\"Accuracy: %.3f%%\" % (results1.mean()*100.0))\n",
    "al_lr=results1.mean()\n",
    "#al_svcr=results2.mean()\n",
    "al_rf=results3.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave one out cross validation (LOOCV) From scikit (With best param, best features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loo_best=data_loo_best.drop('team_1', 1)\n",
    "data_loo_best=data_loo_best.drop('team_2', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using Leave One Out Cross Validation\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "data_loo_best.winner = data_loo_best.winner.apply(to_float)\n",
    "data_loo_best.replace(np.inf, np.nan)\n",
    "data_loo_best = data_loo_best.dropna()\n",
    "data_loo_best = data_loo_best.sample(frac=1)\n",
    "array = data_loo_best.values\n",
    "XX_best = array[:,0:13]\n",
    "YY_best = array[:,13]\n",
    "#print(XX)\n",
    "num_folds = 96\n",
    "#num_instances = len(XX)\n",
    "loocv_best = model_selection.LeaveOneOut()\n",
    "model1_best = LogisticRegression(penalty='l2',C=1.0, solver='saga')\n",
    "#model2_best=SVC(kernel='poly',degree=5,C=1.9952623149688797,gamma=0.1) # svc has problem\n",
    "model3_best = RandomForestClassifier(n_estimators=10,max_depth=8,min_samples_leaf=5,max_leaf_nodes=5)\n",
    "results1_best = model_selection.cross_val_score(model1_best, XX_best, YY_best, cv=loocv_best)\n",
    "#results2_best = model_selection.cross_val_score(model2_best, XX_best, YY_best, cv=loocv_best)\n",
    "results3_best = model_selection.cross_val_score(model3_best, XX_best, YY_best, cv=loocv_best)\n",
    "#print(results)\n",
    "#print(\"Accuracy: %.3f%%\" % (results1.mean()*100.0))\n",
    "al_lr_best_bf=results1_best.mean()\n",
    "#al_svcr_best_bf=results2_best.mean()\n",
    "al_rf_best_bf=results3_best.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave one out cross validation (LOOCV) (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "r_scaler = preprocessing.RobustScaler()\n",
    "s_scaler = preprocessing.StandardScaler()\n",
    "####MOdel Selection ####\n",
    "lr = LogisticRegression(penalty='l2',C=1.0, solver='saga')\n",
    "rf = RandomForestClassifier(n_estimators=10,max_depth=5,min_samples_leaf=10,max_leaf_nodes=2)\n",
    "#svc = SVC(kernel='poly',degree=5,C=1.9952623149688797,gamma=0.1)\n",
    "data = pd.read_csv('FinalDataSet/new/new/.csv')\n",
    "data=data.drop('Unnamed: 0', 1)\n",
    "Team=data.iloc[:,0:2] # Team for check whether the test team is in the training team\n",
    "X = data.iloc[:,0:86] # X for all feature selection including team name\n",
    "y = data.iloc[:,-1] # Y for select the target column like winner\n",
    "confusion_matrix_loo_lr=np.zeros((3, 3))\n",
    "confusion_matrix_loo_rf=np.zeros((3, 3))\n",
    "#confusion_matrix_loo_svc=np.zeros((3, 3))\n",
    "\n",
    "sum_accu=0\n",
    "for j in range(10):\n",
    "    for i in range(63):\n",
    "        # It will test every row from the data set. Fistly, 0th row as test, other 94 as training\n",
    "        team=Team.iloc[i] # select the teams which should be tested\n",
    "        if ((team['team_1']==X['team_2']) & (team['team_2']==X['team_1'])).any(): # it will find out the index number of swaping team \n",
    "            k=X[((team['team_1']==X['team_2']) & (team['team_2']==X['team_1']))].index\n",
    "     \n",
    "    \n",
    "        X_train=X.iloc[0:len(X)] # Every time it will Select the training set including testing and swaping team\n",
    "        X_train=X_train.iloc[:, 2:86] # Now it will exclude the swaping team from the data set\n",
    "    \n",
    "        X_test1=X_train.iloc[i] # With index i , selecting the testing row\n",
    "        X_test2=X_train.iloc[k]\n",
    "        y_test1=y.iloc[i]# testing target value\n",
    "        y_test2=y.iloc[k]\n",
    "        #print('X_test1:', X_test1 )\n",
    "        #print('###############')\n",
    "        #print('X_test2:', X_test2 )\n",
    "    \n",
    "        X_train=X_train.drop(k) # drop the same tested team from training data set\n",
    "        X_train=X_train.drop(i) #drop the testing row from the train set\n",
    "   \n",
    "        y_train=y.iloc[0:len(X)] # Select all target value including the testing and swaping team\n",
    "        y_train=y_train.drop(k)  # drop the same tested team from training data set\n",
    "        y_train=y_train.drop(i)  #drop the testing row from the train set\n",
    "    \n",
    "        X_train=X_train.values\n",
    "        y_train=y_train.apply(to_float)\n",
    "        y_train=y_train.values\n",
    "   \n",
    "    \n",
    "    \n",
    "        X_test1=X_test1.values\n",
    "        X_test1=X_test1.reshape(1, -1)\n",
    "        X_test2=X_test2.values\n",
    "        X_test2=X_test2.reshape(1, -1)\n",
    "        ##### Support vector Machine\n",
    "        #Best Degree: 5\n",
    "        #Best C: 1.9952623149688797\n",
    "        #Best Kernel: poly\n",
    "        #Best Gamma: 0.1\n",
    "        \n",
    "        #### Random forest\n",
    "        #Best n_estimators: 10\n",
    "        #Best max_depth: 5\n",
    "        #Best min_samples_leaf: 10\n",
    "        #Best max_leaf_nodes: 2\n",
    "        #X_train = r_scaler.fit_transform(X_train)\n",
    "        rf.fit(X_train,y_train)\n",
    "        #X_test1 = r_scaler.fit_transform(X_test1)\n",
    "        predict1=rf.predict(X_test1)\n",
    "        confusion_matrix_loo_rf[int(y_test1)][int(predict1)]=confusion_matrix_loo_rf[int(y_test1)][int(predict1)]+1\n",
    "        #X_test2 = r_scaler.fit_transform(X_test2)\n",
    "        predict2=rf.predict(X_test2)\n",
    "        confusion_matrix_loo_rf[int(y_test2)][int(predict2)]=confusion_matrix_loo_rf[int(y_test2)][int(predict2)]+1\n",
    "        ### Logistic regression\n",
    "        #Best Penalty: l2\n",
    "        #Best C: 1.0\n",
    "        #Best solver: saga\n",
    "        \n",
    "        lr.fit(X_train,y_train)\n",
    "        predict1=lr.predict(X_test1)\n",
    "        confusion_matrix_loo_lr[int(y_test1)][int(predict1)]=confusion_matrix_loo_lr[int(y_test1)][int(predict1)]+1\n",
    "        predict2=lr.predict(X_test2)\n",
    "        confusion_matrix_loo_lr[int(y_test2)][int(predict2)]=confusion_matrix_loo_lr[int(y_test2)][int(predict2)]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_loo_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_loo_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "####MOdel Selection ####\n",
    "lr = LogisticRegression(penalty='l2',C=1.0, solver='saga')\n",
    "rf = RandomForestClassifier(n_estimators=10,max_depth=5,min_samples_leaf=10,max_leaf_nodes=2)\n",
    "#svc = SVC(kernel='poly',degree=5,C=1.9952623149688797,gamma=0.1)\n",
    "data = data_loo_manual\n",
    "Team=data.iloc[:,0:2] # Team for check whether the test team is in the training team\n",
    "X = data.iloc[:,0:86] # X for all feature selection including team name\n",
    "y = data.iloc[:,-1] # Y for select the target column like winner\n",
    "confusion_matrix_loo_lr=np.zeros((3, 3))\n",
    "confusion_matrix_loo_rf=np.zeros((3, 3))\n",
    "#confusion_matrix_loo_svc=np.zeros((3, 3))\n",
    "\n",
    "sum_accu=0\n",
    "for j in range(10):\n",
    "    for i in range(48):\n",
    "        # It will test every row from the data set. Fistly, 0th row as test, other 94 as training\n",
    "        team=Team.iloc[i] # select the teams which should be tested\n",
    "        if ((team['team_1']==X['team_2']) & (team['team_2']==X['team_1'])).any(): # it will find out the index number of swaping team \n",
    "            k=X[((team['team_1']==X['team_2']) & (team['team_2']==X['team_1']))].index\n",
    "     \n",
    "    \n",
    "        X_train=X.iloc[0:len(X)] # Every time it will Select the training set including testing and swaping team\n",
    "        X_train=X_train.iloc[:, 2:86] # Now it will exclude the swaping team from the data set\n",
    "    \n",
    "        X_test1=X_train.iloc[i] # With index i , selecting the testing row\n",
    "        X_test2=X_train.iloc[k]\n",
    "        y_test1=y.iloc[i]# testing target value\n",
    "        y_test2=y.iloc[k]\n",
    "        #print('X_test1:', X_test1 )\n",
    "        #print('###############')\n",
    "        #print('X_test2:', X_test2 )\n",
    "    \n",
    "        X_train=X_train.drop(k) # drop the same tested team from training data set\n",
    "        X_train=X_train.drop(i) #drop the testing row from the train set\n",
    "   \n",
    "        y_train=y.iloc[0:len(X)] # Select all target value including the testing and swaping team\n",
    "        y_train=y_train.drop(k)  # drop the same tested team from training data set\n",
    "        y_train=y_train.drop(i)  #drop the testing row from the train set\n",
    "    \n",
    "        X_train=X_train.values\n",
    "        y_train=y_train.apply(to_float)\n",
    "        y_train=y_train.values\n",
    "   \n",
    "    \n",
    "    \n",
    "        X_test1=X_test1.values\n",
    "        X_test1=X_test1.reshape(1, -1)\n",
    "        X_test2=X_test2.values\n",
    "        X_test2=X_test2.reshape(1, -1)\n",
    "        ##### Support vector Machine\n",
    "        #Best Degree: 5\n",
    "        #Best C: 1.9952623149688797\n",
    "        #Best Kernel: poly\n",
    "        #Best Gamma: 0.1\n",
    "        \n",
    "        #### Random forest\n",
    "        #Best n_estimators: 10\n",
    "        #Best max_depth: 5\n",
    "        #Best min_samples_leaf: 10\n",
    "        #Best max_leaf_nodes: 2\n",
    "        \n",
    "        rf.fit(X_train,y_train)\n",
    "        predict1=rf.predict(X_test1)\n",
    "        confusion_matrix_loo_rf[int(y_test1)][int(predict1)]=confusion_matrix_loo_rf[int(y_test1)][int(predict1)]+1\n",
    "        predict2=rf.predict(X_test2)\n",
    "        confusion_matrix_loo_rf[int(y_test2)][int(predict2)]=confusion_matrix_loo_rf[int(y_test2)][int(predict2)]+1\n",
    "        ### Logistic regression\n",
    "        #Best Penalty: l2\n",
    "        #Best C: 1.0\n",
    "        #Best solver: saga\n",
    "        \n",
    "        lr.fit(X_train,y_train)\n",
    "        predict1=lr.predict(X_test1)\n",
    "        confusion_matrix_loo_lr[int(y_test1)][int(predict1)]=confusion_matrix_loo_lr[int(y_test1)][int(predict1)]+1\n",
    "        predict2=lr.predict(X_test2)\n",
    "        confusion_matrix_loo_lr[int(y_test2)][int(predict2)]=confusion_matrix_loo_lr[int(y_test2)][int(predict2)]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_loo_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_loo_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave one out cross validation (LOOCV) (Manual) Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "####MOdel Selection ####\n",
    "lr_best_bf = LogisticRegression(penalty='l2',C=1.0, solver='saga')\n",
    "rf_best_bf = RandomForestClassifier(n_estimators=10,max_depth=5,min_samples_leaf=10,max_leaf_nodes=2)\n",
    "#svc_best_bf = SVC(kernel='poly',degree=5,C=1.9952623149688797,gamma=0.1)\n",
    "data = data_loo_manual\n",
    "\n",
    "data_best=data_loo_manual_best\n",
    "Team=data.iloc[:,0:2] # Team for check whether the test team is in the training team\n",
    "X = data_best.iloc[:,0:15] # X for all feature selection including team name\n",
    "y = data_best.iloc[:,-1] # Y for select the target column like winner\n",
    "confusion_matrix_loo_lr_bf=np.zeros((3, 3))\n",
    "confusion_matrix_loo_rf_bf=np.zeros((3, 3))\n",
    "#confusion_matrix_loo_svc_bf=np.zeros((3, 3))\n",
    "\n",
    "sum_accu=0\n",
    "for j in range(10):\n",
    "    for i in range(48):\n",
    "        # It will test every row from the data set. Fistly, 0th row as test, other 94 as training\n",
    "        team=Team.iloc[i] # select the teams which should be tested\n",
    "        if ((team['team_1']==X['team_2']) & (team['team_2']==X['team_1'])).any(): # it will find out the index number of swaping team \n",
    "            k=X[((team['team_1']==X['team_2']) & (team['team_2']==X['team_1']))].index\n",
    "     \n",
    "        print(j)\n",
    "        X_train=X.iloc[0:len(X)] # Every time it will Select the training set including testing and swaping team\n",
    "        X_train=X_train.iloc[:, 2:15] # Now it will exclude the swaping team from the data set\n",
    "    \n",
    "        X_test1=X_train.iloc[i] # With index i , selecting the testing row\n",
    "        X_test2=X_train.iloc[k]\n",
    "        y_test1=y.iloc[i]# testing target value\n",
    "        y_test2=y.iloc[k]\n",
    "        #print('X_test1:', X_test1 )\n",
    "        #print('###############')\n",
    "        #print('X_test2:', X_test2 )\n",
    "    \n",
    "        X_train=X_train.drop(k) # drop the same tested team from training data set\n",
    "        X_train=X_train.drop(i) #drop the testing row from the train set\n",
    "   \n",
    "        y_train=y.iloc[0:len(X)] # Select all target value including the testing and swaping team\n",
    "        y_train=y_train.drop(k)  # drop the same tested team from training data set\n",
    "        y_train=y_train.drop(i)  #drop the testing row from the train set\n",
    "    \n",
    "        X_train=X_train.values\n",
    "        y_train=y_train.apply(to_float)\n",
    "        y_train=y_train.values\n",
    "   \n",
    "    \n",
    "    \n",
    "        X_test1=X_test1.values\n",
    "        X_test1=X_test1.reshape(1, -1)\n",
    "        X_test2=X_test2.values\n",
    "        X_test2=X_test2.reshape(1, -1)\n",
    "        ##### Support vector Machine\n",
    "        #Best Degree: 5\n",
    "        #Best C: 1.9952623149688797\n",
    "        #Best Kernel: poly\n",
    "        #Best Gamma: 0.1\n",
    "        #svc_best_bf.fit(X_train,y_train)\n",
    "        #predict1=svc_best_bf.predict(X_test1)\n",
    "        #confusion_matrix_loo_svc_bf[int(y_test1)][int(predict1)]=confusion_matrix_loo_svc_bf[int(y_test1)][int(predict1)]+1\n",
    "        #predict2=svc_best_bf.predict(X_test2)\n",
    "        #confusion_matrix_loo_svc_bf[int(y_test2)][int(predict2)]=confusion_matrix_loo_svc_bf[int(y_test2)][int(predict2)]+1\n",
    "        #### Random forest\n",
    "        #Best n_estimators: 10\n",
    "        #Best max_depth: 5\n",
    "        #Best min_samples_leaf: 10\n",
    "        #Best max_leaf_nodes: 2\n",
    "        \n",
    "        rf_best_bf.fit(X_train,y_train)\n",
    "        predict1=rf_best_bf.predict(X_test1)\n",
    "        confusion_matrix_loo_rf_bf[int(y_test1)][int(predict1)]=confusion_matrix_loo_rf_bf[int(y_test1)][int(predict1)]+1\n",
    "        predict2=rf_best_bf.predict(X_test2)\n",
    "        confusion_matrix_loo_rf_bf[int(y_test2)][int(predict2)]=confusion_matrix_loo_rf_bf[int(y_test2)][int(predict2)]+1\n",
    "        ### Logistic regression\n",
    "        #Best Penalty: l2\n",
    "        #Best C: 1.0\n",
    "        #Best solver: saga\n",
    "        \n",
    "        lr_best_bf.fit(X_train,y_train)\n",
    "        predict1=lr_best_bf.predict(X_test1)\n",
    "        confusion_matrix_loo_lr_bf[int(y_test1)][int(predict1)]=confusion_matrix_loo_lr_bf[int(y_test1)][int(predict1)]+1\n",
    "        predict2=lr_best_bf.predict(X_test2)\n",
    "        confusion_matrix_loo_lr_bf[int(y_test2)][int(predict2)]=confusion_matrix_loo_lr_bf[int(y_test2)][int(predict2)]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(confusion_matrix_loo_svc)\n",
    "print(confusion_matrix_loo_lr)\n",
    "print(confusion_matrix_loo_rf)\n",
    "lr_f_score_loo=calculate_f_score_matrix(confusion_matrix_loo_lr)\n",
    "lr_f_score_loo_bf=calculate_f_score_matrix(confusion_matrix_loo_lr_bf)\n",
    "rf_f_score_loo=calculate_f_score_matrix(confusion_matrix_loo_rf)\n",
    "rf_f_score_loo_bf=calculate_f_score_matrix(confusion_matrix_loo_rf_bf)\n",
    "###Before best parameter\n",
    "#print(confusion_matrix_loo_svc_bf)\n",
    "print(confusion_matrix_loo_lr_bf)\n",
    "print(confusion_matrix_loo_rf_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b_svc_tp_sum=confusion_matrix_loo_svc_bf.diagonal().sum()\n",
    "b_lr_tp_sum=confusion_matrix_loo_lr_bf.diagonal().sum()\n",
    "b_rf_tp_sum=confusion_matrix_loo_rf_bf.diagonal().sum()\n",
    "\n",
    "\n",
    "#svc_tp_sum=confusion_matrix_loo_svc.diagonal().sum()\n",
    "lr_tp_sum=confusion_matrix_loo_lr.diagonal().sum()\n",
    "rf_tp_sum=confusion_matrix_loo_rf.diagonal().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_total_rf=confusion_matrix_loo_rf_bf.sum()\n",
    "#print('RF:',total_rf)\n",
    "b_total_lr=confusion_matrix_loo_lr_bf.sum()\n",
    "#print('LR:',total_lr)\n",
    "#b_total_svc=confusion_matrix_loo_svc_bf.sum()\n",
    "#print('SVC:',total_svc)\n",
    "#b_accu_svc=b_svc_tp_sum/float(b_total_rf)\n",
    "b_accu_lr=b_lr_tp_sum/float(b_total_lr)\n",
    "b_accu_rf=b_rf_tp_sum/float(b_total_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rf=confusion_matrix_loo_rf.sum()\n",
    "#print('RF:',total_rf)\n",
    "total_lr=confusion_matrix_loo_lr.sum()\n",
    "#print('LR:',total_lr)\n",
    "#total_svc=confusion_matrix_loo_svc.sum()\n",
    "#print('SVC:',total_svc)\n",
    "#accu_svc=svc_tp_sum/float(total_rf)\n",
    "accu_lr=lr_tp_sum/float(total_lr)\n",
    "accu_rf=rf_tp_sum/float(total_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Manauly Loo With best features\", \"Lr: \", b_accu_lr, \"RF \", b_accu_rf)\n",
    "print(\"Manauly Loo  without best Features\",\"Lr: \", accu_lr,\"RF: \", accu_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize']=(25,10)\n",
    "plt.style.use('ggplot')\n",
    "n = 2\n",
    "#print(\"Manaully\",\"Svc: \", accu_svc, \"Lr: \", accu_lr, \"RF \", accu_rf)\n",
    "#print(\"From Scikit\",\"Svc: \", al_svcr,\"Lr: \", al_lr,\"RF: \", al_rf)\n",
    "#without_CV=(svc_accuracy_score,lr_accuracy_score,rf_accuracy_score)\n",
    "loo_with_bf=(b_accu_lr,b_accu_rf)\n",
    "loo_without_bf=(accu_lr,accu_rf)\n",
    "\n",
    "#Loo_CV_manual=(accu_svc,accu_lr,accu_rf)\n",
    "#milan= (73, 43, 44, 70, 61)\n",
    "#inter = (54, 59, 69, 46, 58)\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n)\n",
    "bar_width = 0.25\n",
    "opacity = 0.9\n",
    "ax.bar(index, loo_with_bf, bar_width, alpha=opacity, color='r',\n",
    "                label='With Best Features')\n",
    "ax.bar(index+bar_width, loo_without_bf, bar_width, alpha=opacity, color='b',label='Without Best Features')\n",
    "\n",
    "#ax.bar(index+bar_width+bar_width, Loo_CV_manual, bar_width, alpha=opacity, color='g', label='LOO CV Manual')\n",
    "ax.set_xlabel('Model',fontsize=30)\n",
    "ax.set_ylabel('Score',fontsize=30)\n",
    "ax.set_title('Model comparison with best Feature and LOO Validation',fontsize=40)\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(('Logistic Regression','Random Forest'),size=30)\n",
    "ax.legend()\n",
    "plt.savefig('Features.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize']=(25,10)\n",
    "plt.style.use('ggplot')\n",
    "n = 2\n",
    "#print(\"Manaully\",\"Svc: \", accu_svc, \"Lr: \", accu_lr, \"RF \", accu_rf)\n",
    "#print(\"From Scikit\",\"Svc: \", al_svcr,\"Lr: \", al_lr,\"RF: \", al_rf)\n",
    "without_CV=(lr_accuracy_score,rf_accuracy_score)\n",
    "Loo_CV_model=(al_lr,al_rf)\n",
    "Loo_CV_manual=(accu_lr,accu_rf)\n",
    "#milan= (73, 43, 44, 70, 61)\n",
    "#inter = (54, 59, 69, 46, 58)\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n)\n",
    "bar_width = 0.25\n",
    "opacity = 0.9\n",
    "ax.bar(index, without_CV, bar_width, alpha=opacity, color='r',\n",
    "                label='Without Cross validation')\n",
    "ax.bar(index+bar_width, Loo_CV_model, bar_width, alpha=opacity, color='b',label='LOO CV Scikit')\n",
    "\n",
    "ax.bar(index+bar_width+bar_width, Loo_CV_manual, bar_width, alpha=opacity, color='g', label='LOO CV Manual')\n",
    "ax.set_xlabel('Model',fontsize=30)\n",
    "ax.set_ylabel('Score',fontsize=30)\n",
    "ax.set_title('Model comparison with cross validation',fontsize=40)\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(('Logistic Regression','Random Forest'),size=30)\n",
    "ax.legend()\n",
    "plt.savefig('cv.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize']=(25,10)\n",
    "plt.style.use('ggplot')\n",
    "n = 4\n",
    "#lr=(lr_precision,lr_recall,lr_f_score,lr_accuracy,lr_accuracy_score)\n",
    "#rf=(rf_precision,rf_recall,rf_f_score,rf_accuracy,rf_accuracy_score)\n",
    "#svc=(svc_precision,svc_recall,svc_f_score,svc_accuracy,svc_accuracy_score)\n",
    "Tie=(svc_precision[0],svc_recall[0],svc_f_score[0],svc_accuracy[0])\n",
    "Team_1_Win=(svc_precision[1],svc_recall[1],svc_f_score[1],svc_accuracy[1])\n",
    "Team_2_Win=(svc_precision[-1],svc_recall[-1],svc_f_score[-1],svc_accuracy[-1])\n",
    "#milan= (73, 43, 44, 70, 61)\n",
    "#inter = (54, 59, 69, 46, 58)\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n)\n",
    "bar_width = 0.25\n",
    "opacity = 0.9\n",
    "ax.bar(index, Tie, bar_width, alpha=opacity, color='r',\n",
    "                label='Tie')\n",
    "ax.bar(index+bar_width, Team_1_Win, bar_width, alpha=opacity, color='b',label='Team_1 Win')\n",
    "\n",
    "ax.bar(index+bar_width+bar_width, Team_2_Win, bar_width, alpha=opacity, color='g', label='Team_2_Win')\n",
    "ax.set_xlabel('Model Evaluation',fontsize=30)\n",
    "ax.set_ylabel('Score',fontsize=30)\n",
    "ax.set_title('Support Vector Classifier',fontsize=40)\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(('Precision','Recall','F-1-Score','Accuracy'),size=30)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "n = 4\n",
    "#lr=(lr_precision,lr_recall,lr_f_score,lr_accuracy,lr_accuracy_score)\n",
    "#rf=(rf_precision,rf_recall,rf_f_score,rf_accuracy,rf_accuracy_score)\n",
    "#svc=(svc_precision,svc_recall,svc_f_score,svc_accuracy,svc_accuracy_score)\n",
    "Tie=(lr_precision[0],lr_recall[0],lr_f_score[0],lr_accuracy[0])\n",
    "Team_1_Win=(lr_precision[1],lr_recall[1],lr_f_score[1],lr_accuracy[1])\n",
    "Team_2_Win=(lr_precision[-1],lr_recall[-1],lr_f_score[-1],lr_accuracy[-1])\n",
    "#milan= (73, 43, 44, 70, 61)\n",
    "#inter = (54, 59, 69, 46, 58)\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n)\n",
    "bar_width = 0.25\n",
    "opacity = 0.9\n",
    "ax.bar(index, Tie, bar_width, alpha=opacity, color='r',label='Tie')\n",
    "ax.bar(index+bar_width, Team_1_Win, bar_width, alpha=opacity, color='b',label='Team_1 Win')\n",
    "ax.bar(index+bar_width+bar_width, Team_2_Win, bar_width, alpha=opacity, color='g', label='Team_2_Win')\n",
    "ax.set_xlabel('Model Evaluation',fontsize=30)\n",
    "ax.set_ylabel('Score',fontsize=30)\n",
    "ax.set_title('Logistic Regression',fontsize=40)\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(('Precision','Recall','F-1-Score','Accuracy'),size=30)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "n = 4\n",
    "#lr=(lr_precision,lr_recall,lr_f_score,lr_accuracy,lr_accuracy_score)\n",
    "#rf=(rf_precision,rf_recall,rf_f_score,rf_accuracy,rf_accuracy_score)\n",
    "#svc=(svc_precision,svc_recall,svc_f_score,svc_accuracy,svc_accuracy_score)\n",
    "Tie=(rf_precision[0],rf_recall[0],rf_f_score[0],rf_accuracy[0])\n",
    "Team_1_Win=(rf_precision[1],rf_recall[1],rf_f_score[1],rf_accuracy[1])\n",
    "Team_2_Win=(rf_precision[-1],rf_recall[-1],rf_f_score[-1],rf_accuracy[-1])\n",
    "#milan= (73, 43, 44, 70, 61)\n",
    "#inter = (54, 59, 69, 46, 58)\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n)\n",
    "bar_width = 0.25\n",
    "opacity = 0.9\n",
    "ax.bar(index, Tie, bar_width, alpha=opacity, color='r',\n",
    "                label='Tie')\n",
    "ax.bar(index+bar_width, Team_1_Win, bar_width, alpha=opacity, color='b',label='Team_1 Win')\n",
    "\n",
    "ax.bar(index+bar_width+bar_width, Team_2_Win, bar_width, alpha=opacity, color='g', label='Team_2_Win')\n",
    "ax.set_xlabel('Model Evaluation',fontsize=30)\n",
    "ax.set_ylabel('Score',fontsize=30)\n",
    "ax.set_title('Random Forest',fontsize=40)\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(('Precision','Recall','F-1-Score','Accuracy'),size=30)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_f_score_bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "n = 8\n",
    "lr=(avg(lr_f_score),lr_accuracy_score,avg(lr_f_score_bf),lr_accuracy_score_bf, avg(lr_f_score_loo), accu_lr,avg(lr_f_score_loo_bf), b_accu_lr)\n",
    "rf=(avg(rf_f_score),rf_accuracy_score,avg(rf_f_score_bf), rf_accuracy_score_bf,avg(rf_f_score_loo), accu_rf,avg(rf_f_score_loo_bf), b_accu_rf)\n",
    "#svc=(avg(svc_precision),avg(svc_recall),avg(svc_f_score),avg(svc_accuracy),svc_accuracy_score)\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n)\n",
    "bar_width = 0.25\n",
    "opacity = 0.9\n",
    "ax.bar(index, lr, bar_width, alpha=opacity, color='y',\n",
    "                label='Logistic Regression')\n",
    "ax.bar(index+bar_width, rf, bar_width, alpha=opacity, color='c',label='Random Forest')\n",
    "\n",
    "#ax.bar(index+bar_width+bar_width, svc, bar_width, alpha=opacity, color='w', label='Support Vector')\n",
    "ax.set_xlabel('Model Evaluation',fontsize=30)\n",
    "ax.set_ylabel('Score',fontsize=30)\n",
    "ax.set_title('Model Comparison',fontsize=40)\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(('F-1-Score with all Features','Accuracy with All features','F-1-Score with Best Features','Accuracy with Best features','F-1 Score:LooCV BPM','Accuracy:LooCV BPM', 'F-1 Score:LooCV BPM BF','Accuracy:LooCV BPM BF '),size=30, rotation=90)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_prediction(wc, team1, team2, model):\n",
    "    match = pd.DataFrame(columns=['fifa_rank1','gdp1','population1','elo1','avg_age1','home_country_adv1','home_continent_adv1','last_best_performance1','star_count1','coach_performance1','final1','semi1','foreign_club1','att1','def1','mid1','ovr1', 'fifa_rank2','gdp2','population2','elo2','avg_age2','home_country_adv2','home_continent_adv2','last_best_performance2','star_count2','coach_performance2','final2','semi2','foreign_club2','att2','def2','mid2','ovr2']\n",
    ", index=[0])\n",
    "    match['fifa_rank1'] = wc[wc.country == team1]['fifa_rank'].iloc[0]\n",
    "    match['gdp1'] = wc[wc.country == team1]['gdp_rank'].iloc[0]\n",
    "    match['population1'] = wc[wc.country == team1]['population_rank'].iloc[0]\n",
    "    match['elo1'] = wc[wc.country == team1]['elo_ranking'].iloc[0]\n",
    "    match['avg_age1'] = wc[wc.country == team1]['avg_age'].iloc[0]\n",
    "    match['home_country_adv1'] = wc[wc.country == team1]['home_country_adv'].iloc[0]\n",
    "    match['home_continent_adv1'] = wc[wc.country == team1]['home_continent_adv'].iloc[0]\n",
    "    match['last_best_performance1'] = wc[wc.country == team1]['last_best_performance'].iloc[0]\n",
    "    match['star_count1'] = wc[wc.country == team1]['star_count'].iloc[0]\n",
    "    match['coach_performance1'] = wc[wc.country == team1]['coach_performance'].iloc[0]\n",
    "    match['final1'] = wc[wc.country == team1]['Previous_final'].iloc[0]\n",
    "    match['semi1'] = wc[wc.country == team1]['Previous_semi_final'].iloc[0]\n",
    "    match['foreign_club1'] = wc[wc.country == team1]['% of player in foreign club'].iloc[0]\n",
    "    match['att1'] = wc[wc.country == team1]['att'].iloc[0]\n",
    "    match['def1'] = wc[wc.country == team1]['def'].iloc[0]\n",
    "    match['mid1'] = wc[wc.country == team1]['mid'].iloc[0]\n",
    "    match['ovr1'] = wc[wc.country == team1]['ovr'].iloc[0]\n",
    "    \n",
    "    match['power_index1'] = wc[wc.country == team1]['spi'].iloc[0]\n",
    "    match['offensive1'] = wc[wc.country == team1]['global_o'].iloc[0]\n",
    "    match['defensive1'] = wc[wc.country == team1]['global_d'].iloc[0]\n",
    "    match['avg_players_appearance1'] = wc[wc.country == team1]['avg_players_appearance'].iloc[0]\n",
    "    match['avg_players_goal1'] = wc[wc.country == team1]['avg_players_goal'].iloc[0]\n",
    "    match['country_happiness_rank1'] = wc[wc.country == team1]['Happiness.Rank'].iloc[0]\n",
    "    \n",
    "    match['fifa_rank2'] = wc[wc.country == team2]['fifa_rank'].iloc[0]\n",
    "    match['gdp2'] = wc[wc.country == team2]['gdp_rank'].iloc[0]\n",
    "    match['population2'] = wc[wc.country == team2]['population_rank'].iloc[0]\n",
    "    match['elo2'] = wc[wc.country == team2]['elo_ranking'].iloc[0]\n",
    "    match['avg_age2'] = wc[wc.country == team2]['avg_age'].iloc[0]\n",
    "    match['home_country_adv2'] = wc[wc.country == team2]['home_country_adv'].iloc[0]\n",
    "    match['home_continent_adv2'] = wc[wc.country == team2]['home_continent_adv'].iloc[0]\n",
    "    match['last_best_performance2'] = wc[wc.country == team2]['last_best_performance'].iloc[0]\n",
    "    match['star_count2'] = wc[wc.country == team2]['star_count'].iloc[0]\n",
    "    match['coach_performance2'] = wc[wc.country == team2]['coach_performance'].iloc[0]\n",
    "    match['final2'] = wc[wc.country == team2]['Previous_final'].iloc[0]\n",
    "    match['semi2'] = wc[wc.country == team2]['Previous_semi_final'].iloc[0]\n",
    "    match['foreign_club2'] = wc[wc.country == team2]['% of player in foreign club'].iloc[0]\n",
    "    match['att2'] = wc[wc.country == team2]['att'].iloc[0]\n",
    "    match['def2'] = wc[wc.country == team2]['def'].iloc[0]\n",
    "    match['mid2'] = wc[wc.country == team2]['mid'].iloc[0]\n",
    "    match['ovr2'] = wc[wc.country == team2]['ovr'].iloc[0]\n",
    "    \n",
    "    match['power_index2'] = wc[wc.country == team1]['spi'].iloc[0]\n",
    "    match['offensive2'] = wc[wc.country == team1]['global_o'].iloc[0]\n",
    "    match['defensive2'] = wc[wc.country == team1]['global_d'].iloc[0]\n",
    "    match['avg_players_appearance2'] = wc[wc.country == team1]['avg_players_appearance'].iloc[0]\n",
    "    match['avg_players_goal2'] = wc[wc.country == team1]['avg_players_goal'].iloc[0]\n",
    "    match['country_happiness_rank2'] = wc[wc.country == team1]['Happiness.Rank'].iloc[0]\n",
    "   \n",
    "    match['fifa_rank'] = match['fifa_rank1'] - match['fifa_rank2']\n",
    "    match['gdp'] = match['gdp1'] - match['gdp2']\n",
    "    match['population'] = match['population1'] - match['population2']\n",
    "    match['avg_age'] = match['avg_age1'] - match['avg_age2']\n",
    "    match['elo'] = match['elo1'] - match['elo2']\n",
    "    match['home_country_adv'] = match['home_country_adv1'] - match['home_country_adv2']\n",
    "    match['home_continent_adv'] = match['home_continent_adv1'] - match['home_continent_adv2']\n",
    "    match['last_best_performance'] = match['last_best_performance1'] - match['last_best_performance2']\n",
    "    match['star_count'] = match['star_count1'] - match['star_count2']\n",
    "    match['coach_performance'] = match['coach_performance1'] - match['coach_performance2']\n",
    "    match['foreign_club'] = match['foreign_club1'] - match['foreign_club2']\n",
    "    match['final'] = match['final1'] - match['final2']\n",
    "    match['semi'] = match['semi1'] - match['semi2']\n",
    "    match['def'] = match['def1'] - match['def2']\n",
    "    match['att'] = match['att1'] - match['att2']\n",
    "    match['mid'] = match['mid1'] - match['mid2']\n",
    "    match['ovr'] = match['ovr1'] - match['ovr2']\n",
    "    match['power_index'] = match['power_index1']-match['power_index2']\n",
    "    match['offensive'] = match['offensive1']-match['offensive2']\n",
    "    match['defensive'] = match['defensive1']-match['defensive2']\n",
    "    match['avg_players_appearance'] = match['avg_players_appearance1']-match['avg_players_appearance2']\n",
    "    match['avg_players_goal1'] = match['avg_players_goal1']-match['avg_players_goal2']\n",
    "    match['country_happiness_rank'] = match['country_happiness_rank1']-match['country_happiness_rank2']\n",
    "\n",
    "   \n",
    "    match_array = match.values\n",
    "    \n",
    "    predict_fract=model.predict_proba(match_array)\n",
    "    prediction = model.predict(match_array)\n",
    "    #print(predict_fract)\n",
    "    \n",
    "    winner = None\n",
    "    \n",
    "    if prediction == 1:\n",
    "        print(\"Winner: \" + team1)\n",
    "    elif prediction == -1:\n",
    "        print(\"Winner: \" + team2)\n",
    "    else:\n",
    "        print(\"The match will be draw\")\n",
    "    \n",
    "    \n",
    "    print(\"*** Probability ***\")\n",
    "    print(\"The probability of winning \"+team1+ \" \"+ '%.2f'%(predict_fract[0][2]*100)+\"%\")\n",
    "    print(\"The probability of winning \"+team2+ \" \" +'%.2f'%(predict_fract[0][0]*100)+\"%\")\n",
    "    print(\"The probability of draw: \" '%.2f'%(predict_fract[0][1]*100)+\"%\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_prediction_with_best_features_parameter_model(wc, team1, team2, model):\n",
    "    match = pd.DataFrame(columns=['last_best_performance','offensive','att','power_index','coach_performance','life_expectancy','gdp','elo','goverment_corruption','generosity','happiness_score','semi','avg_age'],index=[0])\n",
    "    \n",
    "    match['gdp1'] = wc[wc.country == team1]['gdp_rank'].iloc[0]\n",
    "   \n",
    "    match['elo1'] = wc[wc.country == team1]['elo_ranking'].iloc[0]\n",
    "    match['avg_age1'] = wc[wc.country == team1]['avg_age'].iloc[0]\n",
    "    [0]\n",
    "   \n",
    "    match['last_best_performance1'] = wc[wc.country == team1]['last_best_performance'].iloc[0]\n",
    "   \n",
    "    match['coach_performance1'] = wc[wc.country == team1]['coach_performance'].iloc[0]\n",
    "    \n",
    "    match['semi1'] = wc[wc.country == team1]['Previous_semi_final'].iloc[0]\n",
    "   \n",
    "    match['att1'] = wc[wc.country == team1]['att'].iloc[0]\n",
    " \n",
    "    match['power_index1'] = wc[wc.country == team1]['spi'].iloc[0]\n",
    "    \n",
    "    match['offensive1'] = wc[wc.country == team1]['global_o'].iloc[0]\n",
    "    \n",
    "    match['goverment_corruption1'] = wc[wc.country == team1]['Trust..Government.Corruption.'].iloc[0]\n",
    "    match['generosity1'] = wc[wc.country == team1]['Generosity'].iloc[0]\n",
    "    \n",
    "    match['happiness_score1'] = wc[wc.country == team1]['Happiness.Score'].iloc[0]\n",
    "    \n",
    "    match['life_expectancy1'] = wc[wc.country == team1]['Health..Life.Expectancy.'].iloc[0]\n",
    "    \n",
    "    \n",
    "   \n",
    "    match['gdp2'] = wc[wc.country == team2]['gdp_rank'].iloc[0]\n",
    "   \n",
    "    match['elo2'] = wc[wc.country == team2]['elo_ranking'].iloc[0]\n",
    "    match['avg_age2'] = wc[wc.country == team2]['avg_age'].iloc[0]\n",
    "    [0]\n",
    "   \n",
    "    match['last_best_performance2'] = wc[wc.country == team2]['last_best_performance'].iloc[0]\n",
    "   \n",
    "    match['coach_performance2'] = wc[wc.country == team2]['coach_performance'].iloc[0]\n",
    "    \n",
    "    match['semi2'] = wc[wc.country == team2]['Previous_semi_final'].iloc[0]\n",
    "   \n",
    "    match['att2'] = wc[wc.country == team2]['att'].iloc[0]\n",
    " \n",
    "    match['power_index2'] = wc[wc.country == team2]['spi'].iloc[0]\n",
    "    \n",
    "    match['offensive2'] = wc[wc.country == team2]['global_o'].iloc[0]\n",
    "    \n",
    "    match['goverment_corruption2'] = wc[wc.country == team2]['Trust..Government.Corruption.'].iloc[0]\n",
    "    match['generosity2'] = wc[wc.country == team2]['Generosity'].iloc[0]\n",
    "    \n",
    "    match['happiness_score2'] = wc[wc.country == team2]['Happiness.Score'].iloc[0]\n",
    "    \n",
    "    match['life_expectancy2'] = wc[wc.country == team2]['Health..Life.Expectancy.'].iloc[0]\n",
    "    \n",
    "    \n",
    "    match['last_best_performance'] = match['last_best_performance1'] - match['last_best_performance2']\n",
    "    match['offensive'] = match['offensive1']-match['offensive2']\n",
    "    match['gdp'] = match['gdp1'] - match['gdp2']\n",
    "    match['att'] = match['att1'] - match['att2']\n",
    "    match['power_index'] = match['power_index1']-match['power_index2']\n",
    "    match['coach_performance'] = match['coach_performance1'] - match['coach_performance2']\n",
    "    match['life_expectancy'] = match['life_expectancy1'] - match['life_expectancy2']\n",
    "    match['elo'] = match['elo1'] - match['elo2']\n",
    "    match['goverment_corruption'] = match['goverment_corruption1'] - match['goverment_corruption2']\n",
    "    match['generosity'] = match['generosity1'] - match['generosity2']\n",
    "    match['happiness_score'] = match['happiness_score1'] - match['happiness_score2']\n",
    "    match['avg_age'] = match['avg_age1'] - match['avg_age2']\n",
    "    match['semi'] = match['semi1'] - match['semi2']\n",
    "    match=match[['last_best_performance',\n",
    " 'offensive',\n",
    " 'att',\n",
    " 'power_index',\n",
    " 'coach_performance',\n",
    " 'life_expectancy',\n",
    " 'gdp',\n",
    " 'elo',\n",
    " 'goverment_corruption',\n",
    " 'generosity',\n",
    " 'happiness_score',\n",
    " 'semi',\n",
    " 'avg_age']]\n",
    "    match_array = match.values\n",
    "    \n",
    "    predict_fract=model.predict_proba(match_array)\n",
    "    prediction = model.predict(match_array)\n",
    "    #print(predict_fract)\n",
    "    \n",
    "    winner = None\n",
    "    \n",
    "    if prediction == 1:\n",
    "        print(\"Winner: \" + team1)\n",
    "    elif prediction == -1:\n",
    "        print(\"Winner: \" + team2)\n",
    "    else:\n",
    "        print(\"The match will be draw\")\n",
    "    \n",
    "    \n",
    "    print(\"*** Probability ***\")\n",
    "    print(\"The probability of winning \"+team1+ \" \"+ '%.2f'%(predict_fract[0][2]*100)+\"%\")\n",
    "    print(\"The probability of winning \"+team2+ \" \" +'%.2f'%(predict_fract[0][0]*100)+\"%\")\n",
    "    print(\"The probability of draw: \" '%.2f'%(predict_fract[0][1]*100)+\"%\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team_wise_data=team_wise_data.drop('Unnamed: 0', 1)\n",
    "team_wise_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_prediction_with_best_features_parameter_model(team_wise_data, 'sweden', 'england', rf_best_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match_prediction(integrate_features, 'croatia', 'denmark', rf)\n",
    "match_prediction_with_best_features_parameter_model(team_wise_data, 'denmark', 'croatia', rf_best_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_prediction(integrate_features, 'spain', 'russia', rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_prediction(integrate_features,'russia','croatia',rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_prediction(integrate_features, 'uruguay', 'portugal', rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_prediction(integrate_features, 'brazil', 'mexico', rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
